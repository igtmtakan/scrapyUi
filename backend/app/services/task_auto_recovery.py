"""
ã‚¿ã‚¹ã‚¯è‡ªå‹•ä¿®å¾©ã‚µãƒ¼ãƒ“ã‚¹

å¤±æ•—ã¨åˆ¤å®šã•ã‚ŒãŸãŒå®Ÿéš›ã«ã¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•ä¿®å¾©ã™ã‚‹æ©Ÿèƒ½
"""

import json
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import List, Dict, Any

from sqlalchemy.orm import Session
from ..database import SessionLocal, Task as DBTask, TaskStatus, Project as DBProject

logger = logging.getLogger(__name__)

class TaskAutoRecoveryService:
    """ã‚¿ã‚¹ã‚¯è‡ªå‹•ä¿®å¾©ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, base_projects_dir: str = "scrapy_projects"):
        self.base_projects_dir = Path(base_projects_dir)
        
    async def run_auto_recovery(self, hours_back: int = 24) -> Dict[str, Any]:
        """è‡ªå‹•ä¿®å¾©ã‚’å®Ÿè¡Œ"""
        try:
            logger.info(f"ğŸ”§ Starting auto recovery for tasks in last {hours_back} hours")
            
            # éå»Næ™‚é–“ã®å¤±æ•—ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            failed_tasks = self._get_failed_tasks(hours_back)
            logger.info(f"Found {len(failed_tasks)} failed tasks to check")
            
            recovery_results = {
                'checked_tasks': len(failed_tasks),
                'recovered_tasks': 0,
                'recovery_details': []
            }
            
            for task in failed_tasks:
                recovery_result = await self._attempt_task_recovery(task)
                if recovery_result['recovered']:
                    recovery_results['recovered_tasks'] += 1
                    recovery_results['recovery_details'].append(recovery_result)
                    
            logger.info(f"âœ… Auto recovery completed: {recovery_results['recovered_tasks']}/{recovery_results['checked_tasks']} tasks recovered")
            return recovery_results
            
        except Exception as e:
            logger.error(f"Error in auto recovery: {e}")
            return {'error': str(e)}
    
    def _get_failed_tasks(self, hours_back: int) -> List[DBTask]:
        """éå»Næ™‚é–“ã®å¤±æ•—ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
        db = SessionLocal()
        try:
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours_back)
            
            failed_tasks = db.query(DBTask).filter(
                DBTask.status == TaskStatus.FAILED,
                DBTask.created_at >= cutoff_time
            ).all()
            
            return failed_tasks
            
        finally:
            db.close()
    
    async def _attempt_task_recovery(self, task: DBTask) -> Dict[str, Any]:
        """å€‹åˆ¥ã‚¿ã‚¹ã‚¯ã®ä¿®å¾©ã‚’è©¦è¡Œ"""
        try:
            logger.info(f"ğŸ” Checking task {task.id} for recovery")
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’å–å¾—
            db = SessionLocal()
            try:
                project = db.query(DBProject).filter(DBProject.id == task.project_id).first()
                if not project:
                    return {'task_id': task.id, 'recovered': False, 'reason': 'Project not found'}
                
                # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                recovery_data = self._check_result_files(task.id, project.path)
                
                if recovery_data['has_data']:
                    # ã‚¿ã‚¹ã‚¯ã‚’ä¿®å¾©
                    success = self._recover_task(db, task, recovery_data)
                    
                    if success:
                        logger.info(f"âœ… Recovered task {task.id}: {recovery_data['items_count']} items")
                        return {
                            'task_id': task.id,
                            'recovered': True,
                            'items_count': recovery_data['items_count'],
                            'files_found': recovery_data['files_found']
                        }
                    else:
                        return {'task_id': task.id, 'recovered': False, 'reason': 'Recovery failed'}
                else:
                    return {'task_id': task.id, 'recovered': False, 'reason': 'No data files found'}
                    
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"Error recovering task {task.id}: {e}")
            return {'task_id': task.id, 'recovered': False, 'reason': f'Error: {str(e)}'}
    
    def _check_result_files(self, task_id: str, project_path: str) -> Dict[str, Any]:
        """çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            base_filename = f"results_{task_id}"
            project_dir = self.base_projects_dir / project_path
            
            possible_files = [
                project_dir / f"{base_filename}.jsonl",
                project_dir / f"{base_filename}.json",
                project_dir / f"{base_filename}.csv",
                project_dir / f"{base_filename}.xml"
            ]
            
            files_found = []
            total_items = 0
            
            for file_path in possible_files:
                if file_path.exists() and file_path.stat().st_size > 0:
                    files_found.append(str(file_path.name))
                    
                    # JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ æ•°ã‚’å–å¾—
                    if file_path.suffix == '.jsonl':
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                lines = [line.strip() for line in f.readlines() if line.strip()]
                                total_items = max(total_items, len(lines))
                        except Exception as e:
                            logger.warning(f"Error reading JSONL file {file_path}: {e}")
                    
                    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ æ•°ã‚’å–å¾—
                    elif file_path.suffix == '.json':
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                if isinstance(data, list):
                                    total_items = max(total_items, len(data))
                        except Exception as e:
                            logger.warning(f"Error reading JSON file {file_path}: {e}")
            
            return {
                'has_data': len(files_found) > 0 and total_items > 0,
                'files_found': files_found,
                'items_count': total_items
            }
            
        except Exception as e:
            logger.error(f"Error checking result files for task {task_id}: {e}")
            return {'has_data': False, 'files_found': [], 'items_count': 0}
    
    def _recover_task(self, db: Session, task: DBTask, recovery_data: Dict[str, Any]) -> bool:
        """ã‚¿ã‚¹ã‚¯ã‚’ä¿®å¾©"""
        try:
            # ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            task.status = TaskStatus.FINISHED
            task.items_count = recovery_data['items_count']
            task.requests_count = max(recovery_data['items_count'], task.requests_count or 0)
            task.error_count = 0
            
            # å®Œäº†æ™‚åˆ»ã‚’è¨­å®šï¼ˆã¾ã è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
            if not task.finished_at:
                task.finished_at = datetime.now(timezone.utc)
            
            db.commit()
            
            logger.info(f"ğŸ“Š Task {task.id} recovered: status=FINISHED, items={recovery_data['items_count']}")
            return True
            
        except Exception as e:
            logger.error(f"Error updating recovered task {task.id}: {e}")
            db.rollback()
            return False

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
task_auto_recovery_service = TaskAutoRecoveryService()
