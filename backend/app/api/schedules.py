from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
import uuid
from datetime import datetime
from croniter import croniter
from pydantic import BaseModel

from ..database import get_db, Schedule as DBSchedule, Project as DBProject, Spider as DBSpider, Task as DBTask, User as DBUser, UserRole, TaskStatus
from ..models.schemas import Schedule, ScheduleCreate, ScheduleUpdate
from ..tasks.scrapy_tasks import scheduled_spider_run
from ..services.scheduler_service import scheduler_service
from .auth import get_current_active_user

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
class ResetTasksRequest(BaseModel):
    hours_back: int = 24
    cleanup_orphaned: bool = True
    reset_all: bool = False

router = APIRouter(
    responses={
        404: {"description": "Not found"},
        400: {"description": "Bad request"},
        500: {"description": "Internal server error"}
    }
)

@router.get(
    "/",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§å–å¾—",
    description="ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚",
    response_description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ"
)
async def get_schedules(
    project_id: str = None,
    is_active: bool = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_active_user)
):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§å–å¾—

    ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **project_id** (optional): ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    - **is_active** (optional): ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    # JOINã‚¯ã‚¨ãƒªã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æƒ…å ±ã‚’å«ã‚ã‚‹
    query = db.query(
        DBSchedule,
        DBProject.name.label('project_name'),
        DBSpider.name.label('spider_name')
    ).join(
        DBProject, DBSchedule.project_id == DBProject.id
    ).join(
        DBSpider, DBSchedule.spider_id == DBSpider.id
    )

    # ç®¡ç†è€…ã¯å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿
    is_admin = (current_user.role == UserRole.ADMIN or
                current_user.role == "ADMIN" or
                current_user.role == "admin")
    if not is_admin:
        query = query.filter(DBProject.user_id == current_user.id)

    if project_id:
        query = query.filter(DBSchedule.project_id == project_id)
    if is_active is not None:
        query = query.filter(DBSchedule.is_active == is_active)

    results = query.order_by(DBSchedule.created_at.desc()).all()

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’èª¿æ•´
    schedules = []
    for schedule, project_name, spider_name in results:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã«ã‚ˆã‚‹æœ€æ–°ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
        # schedule_idãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
        latest_task = db.query(DBTask).filter(
            DBTask.project_id == schedule.project_id,
            DBTask.spider_id == schedule.spider_id,
            DBTask.schedule_id == schedule.id  # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®ã‚¿ã‚¹ã‚¯ã®ã¿
        ).order_by(DBTask.created_at.desc()).first()

        # Cronå¼ã‹ã‚‰é–“éš”ï¼ˆåˆ†ï¼‰ã‚’æ¨å®š
        interval_minutes = None
        try:
            # ç°¡æ˜“çš„ãªé–“éš”è¨ˆç®—ï¼ˆã‚ˆã‚Šæ­£ç¢ºãªå®Ÿè£…ãŒå¿…è¦ãªå ´åˆã¯æ”¹å–„ï¼‰
            if schedule.cron_expression.startswith("*/"):
                # */7 * * * * å½¢å¼
                parts = schedule.cron_expression.split()
                if len(parts) >= 1 and parts[0].startswith("*/"):
                    interval_minutes = int(parts[0][2:])
            elif " " in schedule.cron_expression:
                # 0 */2 * * * å½¢å¼ï¼ˆæ™‚é–“é–“éš”ï¼‰
                parts = schedule.cron_expression.split()
                if len(parts) >= 2 and parts[1].startswith("*/"):
                    interval_minutes = int(parts[1][2:]) * 60
        except:
            pass

        # æœ€æ–°ã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’å«ã‚ã‚‹
        latest_task_dict = None
        if latest_task:
            # Rich progressã¨åŒã˜æ–¹æ³•ã§å…¨çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            from ..services.scrapy_service import ScrapyPlaywrightService
            scrapy_service = ScrapyPlaywrightService()

            # Scrapyã®çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            full_stats = scrapy_service._get_scrapy_full_stats(latest_task.id, latest_task.project_id)

            # åŸºæœ¬çµ±è¨ˆæƒ…å ±ï¼ˆå„ªå…ˆé †ä½ï¼šScrapyçµ±è¨ˆ > ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å€¤ > 0ï¼‰
            final_items = full_stats.get('items_count', 0) if full_stats else (latest_task.items_count or 0)
            final_requests = full_stats.get('requests_count', 0) if full_stats else (latest_task.requests_count or 0)
            final_responses = full_stats.get('responses_count', 0) if full_stats else 0
            final_errors = full_stats.get('errors_count', 0) if full_stats else (latest_task.error_count or 0)

            # Rich progressçµ±è¨ˆæƒ…å ±ã«åŸºã¥ãã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å†åˆ¤å®š
            original_status = latest_task.status.value if hasattr(latest_task.status, 'value') else latest_task.status
            corrected_status = original_status

            # å¤±æ•—ã¨åˆ¤å®šã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã§ã‚‚ã€ã‚¢ã‚¤ãƒ†ãƒ ãŒå–å¾—ã§ãã¦ã„ã‚Œã°æˆåŠŸã«ä¿®æ­£
            if original_status == 'FAILED' and final_items > 0:
                corrected_status = 'FINISHED'
                print(f"ğŸ”§ Schedule status correction: Task {latest_task.id[:8]}... FAILED â†’ FINISHED (items: {final_items})")

            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã§ã‚‚ã€ã‚¢ã‚¤ãƒ†ãƒ ãŒå–å¾—ã§ãã¦ã„ã‚Œã°æˆåŠŸã«ä¿®æ­£
            elif original_status == 'CANCELLED' and final_items > 0:
                corrected_status = 'FINISHED'
                print(f"ğŸ”§ Schedule status correction: Task {latest_task.id[:8]}... CANCELLED â†’ FINISHED (items: {final_items})")

            latest_task_dict = {
                "id": latest_task.id,
                "status": corrected_status,
                "original_status": original_status,
                "status_corrected": (corrected_status != original_status),
                "items_count": final_items,
                "requests_count": final_requests,
                "responses_count": final_responses,
                "error_count": final_errors,
                "started_at": latest_task.started_at,
                "finished_at": latest_task.finished_at,
                "created_at": latest_task.created_at,
                "rich_stats": full_stats,
                "scrapy_stats_used": bool(full_stats)
            }

        schedule_dict = {
            "id": schedule.id,
            "name": schedule.name,
            "description": schedule.description,
            "cron_expression": schedule.cron_expression,
            "interval_minutes": interval_minutes,
            "project_id": schedule.project_id,
            "spider_id": schedule.spider_id,
            "is_active": schedule.is_active,
            "last_run": schedule.last_run,
            "next_run": schedule.next_run,
            "created_at": schedule.created_at,
            "updated_at": schedule.updated_at,
            "settings": schedule.settings,
            "project_name": project_name,
            "spider_name": spider_name,
            "latest_task": latest_task_dict
        }
        schedules.append(schedule_dict)

    return schedules

@router.get(
    "/{schedule_id}",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°å–å¾—",
    description="æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚",
    response_description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±"
)
async def get_schedule(schedule_id: str, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°å–å¾—

    æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±ã‚’è¿”ã—ã¾ã™
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    # JOINã‚¯ã‚¨ãƒªã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æƒ…å ±ã‚’å«ã‚ã‚‹
    result = db.query(
        DBSchedule,
        DBProject.name.label('project_name'),
        DBSpider.name.label('spider_name')
    ).join(
        DBProject, DBSchedule.project_id == DBProject.id
    ).join(
        DBSpider, DBSchedule.spider_id == DBSpider.id
    ).filter(DBSchedule.id == schedule_id).first()

    if not result:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    schedule, project_name, spider_name = result

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’èª¿æ•´
    schedule_dict = {
        "id": schedule.id,
        "name": schedule.name,
        "description": schedule.description,
        "cron_expression": schedule.cron_expression,
        "project_id": schedule.project_id,
        "spider_id": schedule.spider_id,
        "is_active": schedule.is_active,
        "last_run": schedule.last_run,
        "next_run": schedule.next_run,
        "created_at": schedule.created_at,
        "updated_at": schedule.updated_at,
        "settings": schedule.settings,
        "project_name": project_name,
        "spider_name": spider_name
    }

    return schedule_dict

@router.post(
    "/",
    status_code=status.HTTP_201_CREATED,
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ",
    description="æ–°ã—ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚",
    response_description="ä½œæˆã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æƒ…å ±"
)
async def create_schedule(schedule: ScheduleCreate, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ

    æ–°ã—ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

    ### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    - **name**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
    - **description** (optional): ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª¬æ˜
    - **cron_expression**: Cronå¼ï¼ˆä¾‹: "0 2 * * *" = æ¯æ—¥åˆå‰2æ™‚ï¼‰
    - **project_id**: å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ID
    - **spider_id**: å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®ID
    - **is_active** (optional): ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰
    - **settings** (optional): å®Ÿè¡Œæ™‚ã®è¨­å®š

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **201**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«ä½œæˆã•ã‚ŒãŸå ´åˆ
    - **400**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
    - **404**: æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¾ãŸã¯ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
    project = db.query(DBProject).filter(DBProject.id == schedule.project_id).first()
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found"
        )

    spider = db.query(DBSpider).filter(DBSpider.id == schedule.spider_id).first()
    if not spider:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Spider not found"
        )

    # Cronå¼ã®è©³ç´°æ¤œè¨¼
    try:
        # åŸºæœ¬çš„ãªCronå¼æ¤œè¨¼
        cron = croniter(schedule.cron_expression, datetime.now())
        next_run = cron.get_next(datetime)

        # è¿½åŠ ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        cron_parts = schedule.cron_expression.split()
        if len(cron_parts) != 5:
            raise ValueError("Cron expression must have exactly 5 parts")

        # åˆ†ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ0-59ï¼‰
        minute_part = cron_parts[0]
        if minute_part != '*' and not minute_part.startswith('*/'):
            try:
                minute_val = int(minute_part)
                if minute_val < 0 or minute_val > 59:
                    raise ValueError("Minute must be between 0-59")
            except ValueError:
                pass  # è¤‡é›‘ãªå¼ã¯ croniter ã«ä»»ã›ã‚‹

        # æ™‚é–“ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ0-23ï¼‰
        hour_part = cron_parts[1]
        if hour_part != '*' and not hour_part.startswith('*/'):
            try:
                hour_val = int(hour_part)
                if hour_val < 0 or hour_val > 23:
                    raise ValueError("Hour must be between 0-23")
            except ValueError:
                pass

        # å®Ÿè¡Œé »åº¦ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ1åˆ†æœªæº€ã®å®Ÿè¡Œã‚’é˜²æ­¢ï¼‰
        if minute_part.startswith('*/'):
            interval = int(minute_part[2:])
            if interval == 0:
                raise ValueError("Execution interval cannot be 0")

        # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ãŒå¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
        if next_run <= datetime.now():
            # 1ç§’å¾Œã®æ™‚åˆ»ã§å†è¨ˆç®—
            future_time = datetime.now().replace(second=0, microsecond=0)
            cron = croniter(schedule.cron_expression, future_time)
            next_run = cron.get_next(datetime)

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Invalid cron expression: {str(e)}"
        )

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    existing_schedule = db.query(DBSchedule).filter(
        DBSchedule.name == schedule.name,
        DBSchedule.project_id == schedule.project_id
    ).first()
    if existing_schedule:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Schedule with this name already exists in the project"
        )

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    db_schedule = DBSchedule(
        id=str(uuid.uuid4()),
        name=schedule.name,
        description=schedule.description,
        cron_expression=schedule.cron_expression,
        project_id=schedule.project_id,
        spider_id=schedule.spider_id,
        is_active=schedule.is_active,
        next_run=next_run,
        settings=schedule.settings
    )

    db.add(db_schedule)
    db.commit()
    db.refresh(db_schedule)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’å«ã‚ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    schedule_dict = {
        "id": db_schedule.id,
        "name": db_schedule.name,
        "description": db_schedule.description,
        "cron_expression": db_schedule.cron_expression,
        "project_id": db_schedule.project_id,
        "spider_id": db_schedule.spider_id,
        "is_active": db_schedule.is_active,
        "last_run": db_schedule.last_run,
        "next_run": db_schedule.next_run,
        "created_at": db_schedule.created_at,
        "updated_at": db_schedule.updated_at,
        "settings": db_schedule.settings,
        "project_name": project.name if project else "N/A",
        "spider_name": spider.name if spider else "N/A"
    }

    return schedule_dict

@router.put(
    "/{schedule_id}",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°",
    description="æ—¢å­˜ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚",
    response_description="æ›´æ–°ã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æƒ…å ±"
)
async def update_schedule(
    schedule_id: str,
    schedule_update: ScheduleUpdate,
    db: Session = Depends(get_db)
):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°

    æ—¢å­˜ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: æ›´æ–°ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    - **name** (optional): ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
    - **description** (optional): ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª¬æ˜
    - **cron_expression** (optional): Cronå¼
    - **is_active** (optional): ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹
    - **settings** (optional): å®Ÿè¡Œæ™‚ã®è¨­å®š

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«æ›´æ–°ã•ã‚ŒãŸå ´åˆ
    - **400**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    # æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã®é©ç”¨
    update_data = schedule_update.model_dump(exclude_unset=True)

    # Cronå¼ãŒæ›´æ–°ã•ã‚Œã‚‹å ´åˆã¯æ¤œè¨¼
    if 'cron_expression' in update_data:
        try:
            cron = croniter(update_data['cron_expression'], datetime.now())
            next_run = cron.get_next(datetime)
            update_data['next_run'] = next_run
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Invalid cron expression: {str(e)}"
            )

    for field, value in update_data.items():
        setattr(db_schedule, field, value)

    db.commit()
    db.refresh(db_schedule)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’å–å¾—
    project = db.query(DBProject).filter(DBProject.id == db_schedule.project_id).first()
    spider = db.query(DBSpider).filter(DBSpider.id == db_schedule.spider_id).first()

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’å«ã‚ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    schedule_dict = {
        "id": db_schedule.id,
        "name": db_schedule.name,
        "description": db_schedule.description,
        "cron_expression": db_schedule.cron_expression,
        "project_id": db_schedule.project_id,
        "spider_id": db_schedule.spider_id,
        "is_active": db_schedule.is_active,
        "last_run": db_schedule.last_run,
        "next_run": db_schedule.next_run,
        "created_at": db_schedule.created_at,
        "updated_at": db_schedule.updated_at,
        "settings": db_schedule.settings,
        "project_name": project.name if project else "N/A",
        "spider_name": spider.name if spider else "N/A"
    }

    return schedule_dict

@router.delete(
    "/{schedule_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å‰Šé™¤",
    description="æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚é–¢é€£ã™ã‚‹å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚‚å‰Šé™¤ã•ã‚Œã¾ã™ã€‚"
)
async def delete_schedule(schedule_id: str, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å‰Šé™¤

    æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚é–¢é€£ã™ã‚‹å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚‚å‰Šé™¤ã•ã‚Œã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: å‰Šé™¤ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **204**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚ŒãŸå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    try:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«é–¢é€£ã™ã‚‹å¾…æ©Ÿä¸­ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤
        related_pending_tasks = db.query(DBTask).filter(
            DBTask.project_id == db_schedule.project_id,
            DBTask.spider_id == db_schedule.spider_id,
            DBTask.status == TaskStatus.PENDING
        ).all()

        deleted_tasks_count = 0
        if related_pending_tasks:
            print(f"ğŸ—‘ï¸ Deleting {len(related_pending_tasks)} pending tasks related to schedule {db_schedule.name}")
            for task in related_pending_tasks:
                print(f"  - Deleting pending task: {task.id[:8]}... (created: {task.created_at})")
                db.delete(task)
                deleted_tasks_count += 1

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è‡ªä½“ã‚’å‰Šé™¤
        print(f"ğŸ—‘ï¸ Deleting schedule: {db_schedule.name} (ID: {db_schedule.id})")
        db.delete(db_schedule)

        # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
        db.commit()

        print(f"âœ… Successfully deleted schedule and {deleted_tasks_count} related pending tasks")

    except Exception as e:
        print(f"âš ï¸ Error deleting schedule and related tasks: {str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete schedule and related tasks: {str(e)}"
        )

    return None

@router.post(
    "/{schedule_id}/run",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ‰‹å‹•å®Ÿè¡Œ",
    description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ‰‹å‹•ã§å®Ÿè¡Œã—ã¾ã™ã€‚"
)
async def run_schedule_now(schedule_id: str, db: Session = Depends(get_db), current_user = Depends(get_current_active_user)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ‰‹å‹•å®Ÿè¡Œ

    ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ‰‹å‹•ã§å®Ÿè¡Œã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: å®Ÿè¡Œã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«é–‹å§‹ã•ã‚ŒãŸå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **400**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    if not db_schedule.is_active:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Schedule is not active"
        )

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
    project = db.query(DBProject).filter(DBProject.id == db_schedule.project_id).first()
    spider = db.query(DBSpider).filter(DBSpider.id == db_schedule.spider_id).first()

    if not project or not spider:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project or Spider not found"
        )

    # å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¤‡å®Ÿè¡Œé˜²æ­¢ï¼‰
    running_tasks = db.query(DBTask).filter(
        DBTask.project_id == db_schedule.project_id,
        DBTask.spider_id == db_schedule.spider_id,
        DBTask.status.in_([TaskStatus.RUNNING, TaskStatus.PENDING])
    ).all()

    if running_tasks:
        running_task_info = []
        for task in running_tasks:
            elapsed = (datetime.now() - task.started_at).total_seconds() if task.started_at else 0
            running_task_info.append(f"Task {task.id[:8]}... (running for {elapsed:.0f}s)")

        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Cannot execute schedule: {len(running_tasks)} task(s) already running. {', '.join(running_task_info)}"
        )

    # ã‚¿ã‚¹ã‚¯IDã‚’ç”Ÿæˆ
    import uuid
    task_id = str(uuid.uuid4())

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
    db_task = DBTask(
        id=task_id,
        spider_id=spider.id,
        project_id=project.id,
        user_id=current_user.id,
        status=TaskStatus.PENDING,
        settings=db_schedule.settings or {},
        created_at=datetime.now()
    )
    db.add(db_task)

    # Celeryã‚¿ã‚¹ã‚¯ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿè¡Œï¼ˆscrapy crawlwithwatchdogï¼‰ã‚’é–‹å§‹
    import os
    if not os.getenv("TESTING", False):
        from ..tasks.scrapy_tasks import run_spider_with_watchdog_task

        # Celeryã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œï¼ˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã¨åŒã˜æ–¹å¼ï¼‰
        try:
            celery_task = run_spider_with_watchdog_task.delay(
                project_path=project.path,
                spider_name=spider.name,
                task_id=task_id,
                settings=db_schedule.settings or {}
            )

            # Celeryã‚¿ã‚¹ã‚¯IDã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            db_task.celery_task_id = celery_task.id
            print(f"ğŸš€ Manual execution started with Celery task: {celery_task.id}")

        except Exception as e:
            print(f"âŒ Failed to start Celery task for manual execution: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥å®Ÿè¡Œ
            from ..services.scrapy_service import ScrapyPlaywrightService
            scrapy_service = ScrapyPlaywrightService()

            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿè¡Œã‚’é–‹å§‹
            import threading
            def run_spider_background():
                try:
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    # WebSocketã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
                    def websocket_callback(data: dict):
                        try:
                            from ..api.websocket_progress import broadcast_rich_progress_update
                            asyncio.create_task(broadcast_rich_progress_update(task_id, data))
                        except Exception as e:
                            print(f"âš ï¸ WebSocket callback error in schedule run: {e}")

                    # watchdogç›£è¦–ä»˜ãã§å®Ÿè¡Œ
                    result = loop.run_until_complete(
                        scrapy_service.run_spider_with_watchdog(
                            project_path=project.path,
                            spider_name=spider.name,
                            task_id=task_id,
                            settings=db_schedule.settings or {},
                            websocket_callback=websocket_callback
                        )
                    )
                    print(f"âœ… Schedule spider execution completed: {result}")
                except Exception as e:
                    print(f"âŒ Background schedule spider execution error: {e}")
                finally:
                    loop.close()

            thread = threading.Thread(target=run_spider_background, daemon=True)
            thread.start()

    # æœ€çµ‚å®Ÿè¡Œæ™‚åˆ»ã‚’æ›´æ–°
    db_schedule.last_run = datetime.now()

    # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’è¨ˆç®—
    try:
        cron = croniter(db_schedule.cron_expression, datetime.now())
        db_schedule.next_run = cron.get_next(datetime)
    except Exception:
        pass

    db.commit()

    return {
        "message": "Schedule executed successfully with realtime monitoring",
        "task_id": task_id,
        "schedule_id": schedule_id,
        "realtime": True,
        "command": "scrapy crawlwithwatchdog"
    }

@router.post(
    "/{schedule_id}/toggle",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ",
    description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚"
)
async def toggle_schedule(schedule_id: str, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ

    ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: åˆ‡ã‚Šæ›¿ãˆãŒæ­£å¸¸ã«å®Œäº†ã—ãŸå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    db_schedule.is_active = not db_schedule.is_active
    db.commit()

    return {
        "message": f"Schedule {'activated' if db_schedule.is_active else 'deactivated'}",
        "schedule_id": schedule_id,
        "is_active": db_schedule.is_active
    }

@router.get(
    "/pending-tasks/count",
    summary="å¾…æ©Ÿã‚¿ã‚¹ã‚¯æ•°å–å¾—",
    description="ç¾åœ¨å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚"
)
async def get_pending_tasks_count(db: Session = Depends(get_db)):
    """å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—"""
    try:
        pending_count = db.query(DBTask).filter(DBTask.status == TaskStatus.PENDING).count()

        # å¤ã„ã‚¿ã‚¹ã‚¯ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰ã®æ•°ã‚‚å–å¾—
        from datetime import datetime, timedelta
        cutoff_time = datetime.now() - timedelta(hours=24)
        old_pending_count = db.query(DBTask).filter(
            DBTask.status == TaskStatus.PENDING,
            DBTask.created_at < cutoff_time
        ).count()

        return {
            "total_pending": pending_count,
            "old_pending": old_pending_count,
            "recent_pending": pending_count - old_pending_count
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get pending tasks count: {str(e)}"
        )

@router.post(
    "/pending-tasks/reset",
    summary="å¾…æ©Ÿã‚¿ã‚¹ã‚¯ãƒªã‚»ãƒƒãƒˆ",
    description="å¤ã„å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã¨å­¤ç«‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™ã€‚"
)
async def reset_pending_tasks(
    request: ResetTasksRequest,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_active_user)
):
    """å¤ã„å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã¨å­¤ç«‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
    try:
        from datetime import datetime, timedelta

        # ç®¡ç†è€…æ¨©é™ãƒã‚§ãƒƒã‚¯
        is_admin = (current_user.role == UserRole.ADMIN or
                    current_user.role == "ADMIN" or
                    current_user.role == "admin")

        if not is_admin:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Admin privileges required"
            )

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        hours_back = request.hours_back
        cleanup_orphaned = request.cleanup_orphaned
        reset_all = request.reset_all

        print(f"ğŸ—‘ï¸ Starting task reset process...")
        print(f"  - Hours back: {hours_back}")
        print(f"  - Cleanup orphaned: {cleanup_orphaned}")
        print(f"  - Reset all: {reset_all}")
        print(f"  - User: {current_user.email}")

        cancelled_count = 0
        orphaned_count = 0
        running_count = 0

        if reset_all:
            # å…¨ã¦ã®RUNNINGã¨PENDINGã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            active_tasks = db.query(DBTask).filter(
                DBTask.status.in_([TaskStatus.RUNNING, TaskStatus.PENDING])
            ).all()

            print(f"ğŸ—‘ï¸ Cancelling ALL {len(active_tasks)} active tasks (RUNNING and PENDING)")
            for task in active_tasks:
                if task.status == TaskStatus.RUNNING:
                    print(f"  - Cancelling running task: {task.id[:8]}... (started: {task.started_at})")
                    running_count += 1
                else:
                    print(f"  - Cancelling pending task: {task.id[:8]}... (created: {task.created_at})")
                    cancelled_count += 1

                task.status = TaskStatus.CANCELLED
                task.finished_at = datetime.now()
        else:
            # 1. æŒ‡å®šæ™‚é–“ä»¥ä¸Šå‰ã®å¾…æ©Ÿä¸­ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            old_pending_tasks = db.query(DBTask).filter(
                DBTask.status == TaskStatus.PENDING,
                DBTask.created_at < cutoff_time
            ).all()

            print(f"ğŸ—‘ï¸ Cancelling {len(old_pending_tasks)} old pending tasks (older than {hours_back} hours)")
            for task in old_pending_tasks:
                print(f"  - Cancelling old task: {task.id[:8]}... (created: {task.created_at})")
                task.status = TaskStatus.CANCELLED
                task.finished_at = datetime.now()
                cancelled_count += 1

        # 2. å­¤ç«‹ã—ãŸå¾…æ©Ÿã‚¿ã‚¹ã‚¯ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€reset_allã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if cleanup_orphaned and not reset_all:
            # é–¢é€£ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå­˜åœ¨ã—ãªã„å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            all_pending_tasks = db.query(DBTask).filter(DBTask.status == TaskStatus.PENDING).all()

            for task in all_pending_tasks:
                # å¯¾å¿œã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                related_schedule = db.query(DBSchedule).filter(
                    DBSchedule.project_id == task.project_id,
                    DBSchedule.spider_id == task.spider_id
                ).first()

                if not related_schedule:
                    print(f"ğŸ—‘ï¸ Cancelling orphaned task: {task.id[:8]}... (no related schedule)")
                    task.status = TaskStatus.CANCELLED
                    task.finished_at = datetime.now()
                    orphaned_count += 1

        db.commit()

        # æ®‹ã‚Šã®å¾…æ©Ÿã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—
        remaining_pending = db.query(DBTask).filter(DBTask.status == TaskStatus.PENDING).count()
        remaining_running = db.query(DBTask).filter(DBTask.status == TaskStatus.RUNNING).count()

        if reset_all:
            total_cancelled = cancelled_count + running_count
            message = f"Successfully cancelled ALL active tasks: {running_count} running and {cancelled_count} pending tasks"
        else:
            message_parts = []
            if cancelled_count > 0:
                message_parts.append(f"{cancelled_count} old pending tasks")
            if orphaned_count > 0:
                message_parts.append(f"{orphaned_count} orphaned tasks")

            message = f"Successfully cancelled {' and '.join(message_parts) if message_parts else 'no tasks'}"
            total_cancelled = cancelled_count + orphaned_count

        return {
            "message": message,
            "cancelled_count": cancelled_count,
            "running_count": running_count,
            "orphaned_count": orphaned_count,
            "total_cancelled": total_cancelled,
            "remaining_pending": remaining_pending,
            "remaining_running": remaining_running,
            "hours_back": hours_back,
            "cleanup_orphaned": cleanup_orphaned,
            "reset_all": reset_all
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to reset pending tasks: {str(e)}"
        )

@router.get(
    "/scheduler/status",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ…‹å–å¾—",
    description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ã‚’å–å¾—ã—ã¾ã™ã€‚"
)
async def get_scheduler_status():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ã‚’å–å¾—"""
    try:
        status = scheduler_service.get_status()
        return status
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get scheduler status: {str(e)}"
        )

@router.post(
    "/scheduler/health-check",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯",
    description="å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å•é¡ŒãŒã‚ã‚Œã°ä¿®æ­£ã—ã¾ã™ã€‚"
)
async def scheduler_health_check(db: Session = Depends(get_db)):
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã¨è‡ªå‹•ä¿®æ­£"""
    try:
        # å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—
        schedules = db.query(DBSchedule).all()

        health_report = {
            "timestamp": datetime.now().isoformat(),
            "total_schedules": len(schedules),
            "healthy_schedules": 0,
            "fixed_schedules": 0,
            "error_schedules": 0,
            "issues": [],
            "fixes": []
        }

        for schedule in schedules:
            schedule_issues = []
            schedule_fixes = []

            # 1. Cronå¼ã®æ¤œè¨¼
            try:
                cron = croniter(schedule.cron_expression, datetime.now())
                next_run = cron.get_next(datetime)

                # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’æ›´æ–°ï¼ˆå¤ã„å ´åˆï¼‰
                if not schedule.next_run or schedule.next_run < datetime.now():
                    old_next_run = schedule.next_run
                    schedule.next_run = next_run
                    schedule_fixes.append(f"Updated next_run from {old_next_run} to {next_run}")

            except Exception as e:
                schedule_issues.append(f"Invalid cron expression: {e}")

            # 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
            if not schedule.project:
                schedule_issues.append("Associated project not found")
            if not schedule.spider:
                schedule_issues.append("Associated spider not found")

            # 3. å®Ÿè¡Œé »åº¦ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            try:
                cron_parts = schedule.cron_expression.split()
                if len(cron_parts) >= 1:
                    minute_part = cron_parts[0]
                    if minute_part.startswith('*/'):
                        interval = int(minute_part[2:])
                        if interval < 1:
                            schedule_issues.append("Execution interval too frequent (< 1 minute)")
                        elif interval > 1440:  # 24æ™‚é–“
                            schedule_issues.append("Execution interval too long (> 24 hours)")
            except:
                pass

            # 4. æœ€çµ‚å®Ÿè¡Œæ™‚åˆ»ã®å¦¥å½“æ€§
            if schedule.last_run and schedule.last_run > datetime.now():
                schedule.last_run = None
                schedule_fixes.append("Reset invalid last_run time")

            # çµæœã®é›†è¨ˆ
            if schedule_issues:
                health_report["error_schedules"] += 1
                health_report["issues"].append({
                    "schedule_id": schedule.id,
                    "schedule_name": schedule.name,
                    "issues": schedule_issues
                })
            else:
                health_report["healthy_schedules"] += 1

            if schedule_fixes:
                health_report["fixed_schedules"] += 1
                health_report["fixes"].append({
                    "schedule_id": schedule.id,
                    "schedule_name": schedule.name,
                    "fixes": schedule_fixes
                })

        # ä¿®æ­£ã‚’ã‚³ãƒŸãƒƒãƒˆ
        if health_report["fixed_schedules"] > 0:
            db.commit()

        # å¥å…¨æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        if health_report["total_schedules"] > 0:
            health_score = (health_report["healthy_schedules"] / health_report["total_schedules"]) * 100
            health_report["health_score"] = round(health_score, 1)
        else:
            health_report["health_score"] = 100.0

        return health_report

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to perform health check: {str(e)}"
        )
