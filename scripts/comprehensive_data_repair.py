#!/usr/bin/env python3
"""
ScrapyUI åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ ¹æœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å•é¡Œã‚’è§£æ±ºã—ã¾ã™
"""

import os
import sys
import json
import mysql.connector
from pathlib import Path
from datetime import datetime, timedelta
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ComprehensiveDataRepair:
    def __init__(self):
        self.base_dir = Path("/home/igtmtakan/workplace/python/scrapyUI/scrapy_projects")
        self.db_config = {
            'host': 'localhost',
            'user': 'scrapy_user',
            'password': 'ScrapyUser@2024#',
            'database': 'scrapy_ui'
        }
        self.stats = {
            'repaired_tasks': 0,
            'cleaned_files': 0,
            'synchronized_data': 0,
            'errors': []
        }

    def connect_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        return mysql.connector.connect(**self.db_config)

    def repair_item_counts(self):
        """ã‚¢ã‚¤ãƒ†ãƒ æ•°ã®ä¿®å¾©"""
        logger.info("ğŸ”§ ã‚¢ã‚¤ãƒ†ãƒ æ•°ã®ä¿®å¾©ã‚’é–‹å§‹...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        try:
            # ã‚¢ã‚¤ãƒ†ãƒ æ•°ãŒ0ã®FINISHEDã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            cursor.execute("""
                SELECT t.id, t.spider_name, COUNT(r.id) as actual_count
                FROM tasks t
                LEFT JOIN results r ON t.id = r.task_id
                WHERE t.status = 'FINISHED' AND t.items_count = 0
                GROUP BY t.id, t.spider_name
                HAVING actual_count > 0
            """)
            
            tasks_to_repair = cursor.fetchall()
            logger.info(f"ğŸ“Š ä¿®å¾©å¯¾è±¡ã‚¿ã‚¹ã‚¯: {len(tasks_to_repair)}ä»¶")
            
            for task_id, spider_name, actual_count in tasks_to_repair:
                # ã‚¿ã‚¹ã‚¯ã®ã‚¢ã‚¤ãƒ†ãƒ æ•°ã‚’æ›´æ–°
                cursor.execute("""
                    UPDATE tasks 
                    SET items_count = %s 
                    WHERE id = %s
                """, (actual_count, task_id))
                
                self.stats['repaired_tasks'] += 1
                logger.info(f"âœ… {task_id}: {actual_count}ä»¶ã«ä¿®å¾©")
            
            conn.commit()
            logger.info(f"ğŸ‰ ã‚¢ã‚¤ãƒ†ãƒ æ•°ä¿®å¾©å®Œäº†: {self.stats['repaired_tasks']}ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ ã‚¢ã‚¤ãƒ†ãƒ æ•°ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['errors'].append(f"Item count repair: {e}")
        finally:
            conn.close()

    def synchronize_file_data(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åŒæœŸ"""
        logger.info("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åŒæœŸã‚’é–‹å§‹...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        try:
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            result_files = list(self.base_dir.glob("**/results_*.jsonl"))
            logger.info(f"ğŸ“ æ¤œå‡ºãƒ•ã‚¡ã‚¤ãƒ«: {len(result_files)}ä»¶")
            
            for file_path in result_files:
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ã‚¹ã‚¯IDã‚’æŠ½å‡º
                    task_id = file_path.stem.replace("results_", "")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã‚¢ã‚¤ãƒ†ãƒ æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_items = sum(1 for line in f if line.strip())
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ã‚¢ã‚¤ãƒ†ãƒ æ•°ã‚’ç¢ºèª
                    cursor.execute("SELECT items_count FROM tasks WHERE id = %s", (task_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        db_items = result[0]
                        if db_items != file_items:
                            # ä¸æ•´åˆã‚’ä¿®æ­£
                            cursor.execute("""
                                UPDATE tasks 
                                SET items_count = %s 
                                WHERE id = %s
                            """, (file_items, task_id))
                            
                            self.stats['synchronized_data'] += 1
                            logger.info(f"ğŸ”§ {task_id}: {db_items} â†’ {file_items}")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            
            conn.commit()
            logger.info(f"âœ… åŒæœŸå®Œäº†: {self.stats['synchronized_data']}ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['errors'].append(f"File sync: {e}")
        finally:
            conn.close()

    def cleanup_orphaned_files(self):
        """å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ§¹ å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        try:
            # å…¨ã‚¿ã‚¹ã‚¯IDã‚’å–å¾—
            cursor.execute("SELECT id FROM tasks")
            valid_task_ids = {row[0] for row in cursor.fetchall()}
            
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            result_files = list(self.base_dir.glob("**/results_*.jsonl"))
            
            for file_path in result_files:
                try:
                    task_id = file_path.stem.replace("results_", "")
                    
                    if task_id not in valid_task_ids:
                        # å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                        file_path.unlink()
                        self.stats['cleaned_files'] += 1
                        logger.info(f"ğŸ—‘ï¸ å‰Šé™¤: {file_path.name}")
                
                except Exception as e:
                    logger.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            
            logger.info(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {self.stats['cleaned_files']}ä»¶å‰Šé™¤")
            
        except Exception as e:
            logger.error(f"âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['errors'].append(f"File cleanup: {e}")
        finally:
            conn.close()

    def optimize_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–"""
        logger.info("âš¡ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–ã‚’é–‹å§‹...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        try:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
            cursor.execute("OPTIMIZE TABLE tasks")
            cursor.execute("OPTIMIZE TABLE results")
            cursor.execute("OPTIMIZE TABLE projects")
            cursor.execute("OPTIMIZE TABLE spiders")
            
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['errors'].append(f"DB optimization: {e}")
        finally:
            conn.close()

    def generate_report(self):
        """ä¿®å¾©ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("ğŸ“‹ ä¿®å¾©ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ...")
        
        report = f"""
ğŸ”§ ScrapyUI ãƒ‡ãƒ¼ã‚¿ä¿®å¾©ãƒ¬ãƒãƒ¼ãƒˆ
{'='*50}
å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š ä¿®å¾©çµæœ:
- ä¿®å¾©ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯: {self.stats['repaired_tasks']}ä»¶
- åŒæœŸã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿: {self.stats['synchronized_data']}ä»¶  
- å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {self.stats['cleaned_files']}ä»¶

âŒ ã‚¨ãƒ©ãƒ¼: {len(self.stats['errors'])}ä»¶
{chr(10).join(f'  - {error}' for error in self.stats['errors'])}

âœ… ä¿®å¾©å®Œäº†
"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_file = Path("data_repair_report.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(report)
        logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")

    def run_comprehensive_repair(self):
        """åŒ…æ‹¬çš„ä¿®å¾©ã®å®Ÿè¡Œ"""
        logger.info("ğŸš€ åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ä¿®å¾©ã‚’é–‹å§‹...")
        start_time = datetime.now()
        
        try:
            # Phase 1: ã‚¢ã‚¤ãƒ†ãƒ æ•°ä¿®å¾©
            self.repair_item_counts()
            
            # Phase 2: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»DBåŒæœŸ
            self.synchronize_file_data()
            
            # Phase 3: å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            self.cleanup_orphaned_files()
            
            # Phase 4: DBæœ€é©åŒ–
            self.optimize_database()
            
            # Phase 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.generate_report()
            
            duration = datetime.now() - start_time
            logger.info(f"ğŸ‰ åŒ…æ‹¬çš„ä¿®å¾©å®Œäº† (æ‰€è¦æ™‚é–“: {duration})")
            
        except Exception as e:
            logger.error(f"âŒ åŒ…æ‹¬çš„ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            raise

if __name__ == "__main__":
    repair = ComprehensiveDataRepair()
    repair.run_comprehensive_repair()
