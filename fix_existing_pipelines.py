#!/usr/bin/env python3
"""
æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®pipelines.pyã‚’ä¿®æ­£
DBä¿å­˜æœ‰åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æ­£ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šã‚’é©ç”¨
"""
import sqlite3
import os
from pathlib import Path

def fix_existing_pipelines():
    """æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®pipelines.pyã‚’ä¿®æ­£"""
    
    print("ğŸ”§ æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®pipelines.pyä¿®æ­£é–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
    db_path = Path("backend/database/scrapy_ui.db")
    
    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return False
    
    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # DBä¿å­˜æœ‰åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        cursor.execute("""
            SELECT id, name, path, db_save_enabled 
            FROM projects 
            WHERE db_save_enabled = 1
        """)
        
        enabled_projects = cursor.fetchall()
        
        print(f"ğŸ“Š DBä¿å­˜æœ‰åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {len(enabled_projects)}ä»¶")
        
        for project_id, project_name, project_path, db_save_enabled in enabled_projects:
            print(f"\nğŸ”„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¿®æ­£ä¸­: {project_name}")
            fix_project_pipelines(project_name, project_path, True)
        
        # DBä¿å­˜ç„¡åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚‚ç¢ºèª
        cursor.execute("""
            SELECT id, name, path, db_save_enabled 
            FROM projects 
            WHERE db_save_enabled = 0
        """)
        
        disabled_projects = cursor.fetchall()
        
        print(f"\nğŸ“Š DBä¿å­˜ç„¡åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {len(disabled_projects)}ä»¶")
        
        for project_id, project_name, project_path, db_save_enabled in disabled_projects:
            print(f"\nğŸ”„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¿®æ­£ä¸­: {project_name}")
            fix_project_pipelines(project_name, project_path, False)
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    finally:
        if 'conn' in locals():
            conn.close()

def fix_project_pipelines(project_name: str, project_path: str, db_save_enabled: bool):
    """å€‹åˆ¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®pipelines.pyã‚’ä¿®æ­£"""
    
    # pipelines.pyãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ¢ã™
    scrapy_projects_dir = Path("scrapy_projects")
    
    possible_paths = [
        scrapy_projects_dir / project_path / project_path / "pipelines.py",
        scrapy_projects_dir / project_path / "pipelines.py",
        scrapy_projects_dir / project_name / project_name / "pipelines.py",
        scrapy_projects_dir / project_name / "pipelines.py",
    ]
    
    pipelines_file = None
    for path in possible_paths:
        if path.exists():
            pipelines_file = path
            break
    
    if not pipelines_file:
        print(f"  âŒ pipelines.pyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {project_name}")
        print(f"     ç¢ºèªã—ãŸãƒ‘ã‚¹:")
        for path in possible_paths:
            print(f"       - {path}")
        return False
    
    print(f"  ğŸ“„ pipelines.pyãƒ•ã‚¡ã‚¤ãƒ«: {pipelines_file}")
    
    # ç¾åœ¨ã®å†…å®¹ã‚’ç¢ºèª
    try:
        with open(pipelines_file, 'r', encoding='utf-8') as f:
            current_content = f.read()
        
        # ScrapyUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        has_scrapy_ui_pipeline = 'ScrapyUIDatabasePipeline' in current_content
        
        print(f"  ğŸ“Š ç¾åœ¨ã®çŠ¶æ…‹:")
        print(f"     DBä¿å­˜è¨­å®š: {'æœ‰åŠ¹' if db_save_enabled else 'ç„¡åŠ¹'}")
        print(f"     ScrapyUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {'ã‚ã‚Š' if has_scrapy_ui_pipeline else 'ãªã—'}")
        
        # ä¿®æ­£ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
        needs_fix = False
        
        if db_save_enabled and not has_scrapy_ui_pipeline:
            print(f"  âš ï¸ DBä¿å­˜æœ‰åŠ¹ãªã®ã«ScrapyUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
            needs_fix = True
        elif not db_save_enabled and has_scrapy_ui_pipeline:
            print(f"  âš ï¸ DBä¿å­˜ç„¡åŠ¹ãªã®ã«ScrapyUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒã‚ã‚Šã¾ã™")
            needs_fix = True
        
        if needs_fix:
            # æ­£ã—ã„å†…å®¹ã‚’ç”Ÿæˆ
            if db_save_enabled:
                # DBä¿å­˜æœ‰åŠ¹: ScrapyUIãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œç‰ˆ
                new_content = generate_db_enabled_pipelines(project_name)
                print(f"  ğŸ”§ DBä¿å­˜æœ‰åŠ¹ç‰ˆpipelines.pyã‚’ç”Ÿæˆ")
            else:
                # DBä¿å­˜ç„¡åŠ¹: åŸºæœ¬çš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã¿
                new_content = generate_db_disabled_pipelines(project_name)
                print(f"  ğŸ”§ DBä¿å­˜ç„¡åŠ¹ç‰ˆpipelines.pyã‚’ç”Ÿæˆ")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
            with open(pipelines_file, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            print(f"  âœ… pipelines.pyã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            print(f"  âœ… pipelines.pyã¯æ­£ã—ã„çŠ¶æ…‹ã§ã™")
        
        return True
        
    except Exception as e:
        print(f"  âŒ pipelines.pyä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def generate_db_enabled_pipelines(project_name: str) -> str:
    """DBä¿å­˜æœ‰åŠ¹ç‰ˆpipelines.pyã‚’ç”Ÿæˆ"""
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’ã‚¯ãƒ©ã‚¹åã«å¤‰æ›ï¼ˆæœ€åˆã®æ–‡å­—ã‚’å¤§æ–‡å­—ã«ï¼‰
    class_name = project_name.replace('_', '').replace('-', '').capitalize()
    
    return f'''# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html

# useful for handling different item types with a single interface
from itemadapter import ItemAdapter

# ScrapyUI ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
from pathlib import Path

# ScrapyUIã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¹ã‚’è¿½åŠ 
scrapy_ui_backend = Path(__file__).parent.parent.parent.parent / "backend"
sys.path.insert(0, str(scrapy_ui_backend))

try:
    from app.templates.database_pipeline import ScrapyUIDatabasePipeline, ScrapyUIJSONPipeline
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    class ScrapyUIDatabasePipeline:
        def process_item(self, item, spider):
            return item

    class ScrapyUIJSONPipeline:
        def process_item(self, item, spider):
            return item


class {class_name}Pipeline:
    """
    åŸºæœ¬çš„ãªã‚¢ã‚¤ãƒ†ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """

    def process_item(self, item, spider):
        # ã‚¢ã‚¤ãƒ†ãƒ ã®åŸºæœ¬çš„ãªå‡¦ç†
        return item


# ScrapyUIãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®è¨­å®šã§ç›´æ¥å‚ç…§ã§ãã¾ã™
__all__ = ['ScrapyUIDatabasePipeline', 'ScrapyUIJSONPipeline', '{class_name}Pipeline']
'''

def generate_db_disabled_pipelines(project_name: str) -> str:
    """DBä¿å­˜ç„¡åŠ¹ç‰ˆpipelines.pyã‚’ç”Ÿæˆ"""
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’ã‚¯ãƒ©ã‚¹åã«å¤‰æ›ï¼ˆæœ€åˆã®æ–‡å­—ã‚’å¤§æ–‡å­—ã«ï¼‰
    class_name = project_name.replace('_', '').replace('-', '').capitalize()
    
    return f'''# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html

# useful for handling different item types with a single interface
from itemadapter import ItemAdapter


class {class_name}Pipeline:
    """
    åŸºæœ¬çš„ãªã‚¢ã‚¤ãƒ†ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """

    def process_item(self, item, spider):
        # ã‚¢ã‚¤ãƒ†ãƒ ã®åŸºæœ¬çš„ãªå‡¦ç†
        return item


# æ³¨æ„: ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯DBä¿å­˜ãŒç„¡åŠ¹ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™
# çµæœã¯ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã®ã¿ã«ãªã‚Šã¾ã™
# DBä¿å­˜ã‚’æœ‰åŠ¹ã«ã—ãŸã„å ´åˆã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‚’å¤‰æ›´ã—ã¦ãã ã•ã„

__all__ = ['{class_name}Pipeline']
'''

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¯ æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®pipelines.pyä¿®æ­£ãƒ„ãƒ¼ãƒ«")
    
    success = fix_existing_pipelines()
    
    if success:
        print("\nğŸ‰ ä¿®æ­£å®Œäº†ï¼")
        print("\nğŸ”§ ä¿®æ­£å†…å®¹:")
        print("  âœ… DBä¿å­˜æœ‰åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ScrapyUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œç‰ˆã«æ›´æ–°")
        print("  âœ… DBä¿å­˜ç„¡åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: åŸºæœ¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç‰ˆã«æ›´æ–°")
        print("  âœ… æ—¢ã«æ­£ã—ã„çŠ¶æ…‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: å¤‰æ›´ãªã—")
        
        print("\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. ä¿®æ­£ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’å®Ÿè¡Œ")
        print("  2. DBä¿å­˜æœ‰åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çµæœãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª")
        print("  3. DBä¿å­˜ç„¡åŠ¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çµæœãŒãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã«å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª")
    else:
        print("\nâŒ ä¿®æ­£å¤±æ•—")

if __name__ == "__main__":
    main()
