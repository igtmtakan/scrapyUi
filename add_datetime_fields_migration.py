#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: Resultãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆæ—¥æ™‚ã¨å–å¾—æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
"""

import sqlite3
import os
from pathlib import Path
from datetime import datetime

def add_datetime_fields():
    """Resultãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆæ—¥æ™‚ã¨å–å¾—æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ """
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    db_path = Path("backend/database/scrapy_ui.db")
    
    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return False
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # æ—¢å­˜ã®ã‚«ãƒ©ãƒ ã‚’ç¢ºèª
        cursor.execute("PRAGMA table_info(results)")
        columns = [column[1] for column in cursor.fetchall()]
        
        print("ğŸ” ç¾åœ¨ã®Resultãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :")
        for column in columns:
            print(f"  - {column}")
        
        # crawl_start_datetimeã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        if 'crawl_start_datetime' not in columns:
            print("\nğŸ”§ crawl_start_datetimeã‚«ãƒ©ãƒ ã‚’è¿½åŠ ä¸­...")
            cursor.execute("""
                ALTER TABLE results 
                ADD COLUMN crawl_start_datetime DATETIME
            """)
            print("âœ… crawl_start_datetimeã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ")
        else:
            print("âœ… crawl_start_datetimeã‚«ãƒ©ãƒ ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
        
        # item_acquired_datetimeã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        if 'item_acquired_datetime' not in columns:
            print("\nğŸ”§ item_acquired_datetimeã‚«ãƒ©ãƒ ã‚’è¿½åŠ ä¸­...")
            cursor.execute("""
                ALTER TABLE results 
                ADD COLUMN item_acquired_datetime DATETIME
            """)
            print("âœ… item_acquired_datetimeã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ")
        else:
            print("âœ… item_acquired_datetimeã‚«ãƒ©ãƒ ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
        
        # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
        conn.commit()
        
        # è¿½åŠ ã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        cursor.execute("PRAGMA table_info(results)")
        updated_columns = [column[1] for column in cursor.fetchall()]
        
        print("\nğŸ“‹ æ›´æ–°å¾Œã®Resultãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :")
        for column in cursor.fetchall():
            print(f"  - {column[1]} ({column[2]})")
        
        # æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¿½åŠ ã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        if 'crawl_start_datetime' in updated_columns and 'item_acquired_datetime' in updated_columns:
            print("\nâœ… ä¸¡æ–¹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ­£å¸¸ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸ")
            return True
        else:
            print("\nâŒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    finally:
        if 'conn' in locals():
            conn.close()

def update_existing_data():
    """æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã«æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¨­å®š"""
    
    db_path = Path("backend/database/scrapy_ui.db")
    
    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        print("\nğŸ”„ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°ä¸­...")
        
        # æ—¢å­˜ã®resultsãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèª
        cursor.execute("SELECT COUNT(*) FROM results")
        total_results = cursor.fetchone()[0]
        print(f"ğŸ“Š æ—¢å­˜çµæœãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_results}ä»¶")
        
        if total_results > 0:
            # æ—¢å­˜ã®resultsãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆtask_idã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
            cursor.execute("""
                SELECT DISTINCT r.task_id, t.started_at, t.finished_at
                FROM results r
                LEFT JOIN tasks t ON r.task_id = t.id
                WHERE r.crawl_start_datetime IS NULL OR r.item_acquired_datetime IS NULL
            """)
            
            task_info = cursor.fetchall()
            
            updated_count = 0
            for task_id, started_at, finished_at in task_info:
                if task_id:
                    # ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆæ—¥æ™‚ã¯ã‚¿ã‚¹ã‚¯ã®é–‹å§‹æ™‚åˆ»ã‚’ä½¿ç”¨
                    crawl_start = started_at if started_at else datetime.now().isoformat()
                    
                    # ã‚¢ã‚¤ãƒ†ãƒ å–å¾—æ—¥æ™‚ã¯ã‚¿ã‚¹ã‚¯ã®å®Œäº†æ™‚åˆ»ã‚’ä½¿ç”¨ï¼ˆãªã‘ã‚Œã°ç¾åœ¨æ™‚åˆ»ï¼‰
                    item_acquired = finished_at if finished_at else datetime.now().isoformat()
                    
                    # è©²å½“ã™ã‚‹resultsãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°
                    cursor.execute("""
                        UPDATE results 
                        SET crawl_start_datetime = ?, 
                            item_acquired_datetime = ?
                        WHERE task_id = ? 
                        AND (crawl_start_datetime IS NULL OR item_acquired_datetime IS NULL)
                    """, (crawl_start, item_acquired, task_id))
                    
                    updated_count += cursor.rowcount
            
            conn.commit()
            print(f"âœ… {updated_count}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            print("ğŸ“ æ›´æ–°å¯¾è±¡ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    finally:
        if 'conn' in locals():
            conn.close()

def verify_migration():
    """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¤œè¨¼"""
    
    db_path = Path("backend/database/scrapy_ui.db")
    
    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        print("\nğŸ” ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼:")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’ç¢ºèª
        cursor.execute("PRAGMA table_info(results)")
        columns = cursor.fetchall()
        
        print("Resultãƒ†ãƒ¼ãƒ–ãƒ«ã®å…¨ã‚«ãƒ©ãƒ :")
        
        crawl_start_found = False
        item_acquired_found = False
        
        for column in columns:
            column_name = column[1]
            column_type = column[2]
            is_nullable = "NULL" if column[3] == 0 else "NOT NULL"
            
            if column_name == 'crawl_start_datetime':
                crawl_start_found = True
                print(f"  âœ… {column_name} ({column_type}) {is_nullable}")
            elif column_name == 'item_acquired_datetime':
                item_acquired_found = True
                print(f"  âœ… {column_name} ({column_type}) {is_nullable}")
            else:
                print(f"  - {column_name} ({column_type}) {is_nullable}")
        
        if crawl_start_found and item_acquired_found:
            print("\nâœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸ: ä¸¡æ–¹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ­£å¸¸ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸ")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
            cursor.execute("""
                SELECT id, crawl_start_datetime, item_acquired_datetime 
                FROM results 
                WHERE crawl_start_datetime IS NOT NULL 
                LIMIT 3
            """)
            
            sample_data = cursor.fetchall()
            if sample_data:
                print("\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:")
                for result_id, crawl_start, item_acquired in sample_data:
                    print(f"  - {result_id}: ã‚¯ãƒ­ãƒ¼ãƒ«é–‹å§‹={crawl_start}, ã‚¢ã‚¤ãƒ†ãƒ å–å¾—={item_acquired}")
            
            return True
        else:
            print("\nâŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
    except Exception as e:
        print(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    finally:
        if 'conn' in locals():
            conn.close()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
    print("ç›®çš„: Resultãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆæ—¥æ™‚ã¨å–å¾—æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ")
    
    # 1. ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ 
    success = add_datetime_fields()
    
    if success:
        # 2. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        update_existing_data()
        
        # 3. æ¤œè¨¼å®Ÿè¡Œ
        verify_migration()
        
        print("\nğŸ‰ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
        print("ã“ã‚Œã§ã€å„çµæœã‚¢ã‚¤ãƒ†ãƒ ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆæ—¥æ™‚ã¨å–å¾—æ—¥æ™‚ãŒè¨˜éŒ²ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚")
        print("\nğŸ“‹ æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:")
        print("  - crawl_start_datetime: ã‚¯ãƒ­ãƒ¼ãƒ«é–‹å§‹æ—¥æ™‚")
        print("  - item_acquired_datetime: ã‚¢ã‚¤ãƒ†ãƒ å–å¾—æ—¥æ™‚")
    else:
        print("\nâŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—")
        return False
    
    return True

if __name__ == "__main__":
    main()
