#!/usr/bin/env python3
"""
JSONLãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã«ã‚ˆã‚‹DBè‡ªå‹•ã‚¤ãƒ³ã‚µãƒ¼ãƒˆå®Ÿè£…ä¾‹
"""
import json
import asyncio
import sqlite3
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, Callable
import uuid

# æ–¹æ³•1: watchdogãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ï¼‰
try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler
    WATCHDOG_AVAILABLE = True
except ImportError:
    WATCHDOG_AVAILABLE = False
    print("âš ï¸ watchdogãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("   ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install watchdog")

class JSONLFileMonitor:
    """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›£è¦–ã—ã¦DBã«è‡ªå‹•ã‚¤ãƒ³ã‚µãƒ¼ãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 db_path: str,
                 task_id: str,
                 project_id: str,
                 spider_name: str,
                 websocket_callback: Optional[Callable] = None):
        self.db_path = db_path
        self.task_id = task_id
        self.project_id = project_id
        self.spider_name = spider_name
        self.websocket_callback = websocket_callback
        self.processed_lines = 0
        self.is_monitoring = False
        self.observer = None
        
    async def start_monitoring(self, jsonl_file_path: str):
        """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã®ç›£è¦–ã‚’é–‹å§‹"""
        self.jsonl_file_path = Path(jsonl_file_path)
        self.is_monitoring = True
        
        print(f"ğŸ” JSONLãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹: {self.jsonl_file_path}")
        
        if WATCHDOG_AVAILABLE:
            await self._start_watchdog_monitoring()
        else:
            await self._start_polling_monitoring()
    
    async def _start_watchdog_monitoring(self):
        """watchdogãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸç›£è¦–"""
        
        class JSONLEventHandler(FileSystemEventHandler):
            def __init__(self, monitor):
                self.monitor = monitor
                
            def on_modified(self, event):
                if not event.is_directory and event.src_path == str(self.monitor.jsonl_file_path):
                    asyncio.create_task(self.monitor._process_new_lines())
        
        event_handler = JSONLEventHandler(self)
        self.observer = Observer()
        self.observer.schedule(event_handler, str(self.jsonl_file_path.parent), recursive=False)
        self.observer.start()
        
        print(f"âœ… watchdogç›£è¦–é–‹å§‹: {self.jsonl_file_path.parent}")
        
        try:
            while self.is_monitoring:
                await asyncio.sleep(1)
        finally:
            self.observer.stop()
            self.observer.join()
    
    async def _start_polling_monitoring(self):
        """ãƒãƒ¼ãƒªãƒ³ã‚°æ–¹å¼ã®ç›£è¦–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        print(f"ğŸ”„ ãƒãƒ¼ãƒªãƒ³ã‚°ç›£è¦–é–‹å§‹ï¼ˆ1ç§’é–“éš”ï¼‰")
        
        while self.is_monitoring:
            await self._process_new_lines()
            await asyncio.sleep(1)
    
    async def _process_new_lines(self):
        """æ–°ã—ã„è¡Œã‚’å‡¦ç†ã—ã¦DBã«ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ"""
        try:
            if not self.jsonl_file_path.exists():
                return
            
            with open(self.jsonl_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # æ–°ã—ã„è¡Œã®ã¿å‡¦ç†
            new_lines = lines[self.processed_lines:]
            
            if new_lines:
                print(f"ğŸ“ æ–°ã—ã„è¡Œã‚’æ¤œå‡º: {len(new_lines)}ä»¶")
                
                for line in new_lines:
                    line = line.strip()
                    if line:
                        await self._insert_item_to_db(line)
                        self.processed_lines += 1
                
                # WebSocketé€šçŸ¥
                if self.websocket_callback:
                    await self.websocket_callback({
                        'type': 'items_update',
                        'task_id': self.task_id,
                        'new_items': len(new_lines),
                        'total_items': self.processed_lines
                    })
        
        except Exception as e:
            print(f"âŒ è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _insert_item_to_db(self, json_line: str):
        """å˜ä¸€ã‚¢ã‚¤ãƒ†ãƒ ã‚’DBã«ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ"""
        try:
            # JSONè§£æ
            item_data = json.loads(json_line)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ
            item_id = str(uuid.uuid4())
            cursor.execute("""
                INSERT INTO scraped_items 
                (id, task_id, project_id, spider_name, data, scraped_at, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                item_id,
                self.task_id,
                self.project_id,
                self.spider_name,
                json.dumps(item_data, ensure_ascii=False),
                datetime.now().isoformat(),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… DBã‚¤ãƒ³ã‚µãƒ¼ãƒˆæˆåŠŸ: {item_id}")
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {e} - Line: {json_line[:100]}...")
        except Exception as e:
            print(f"âŒ DBã‚¤ãƒ³ã‚µãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop_monitoring(self):
        """ç›£è¦–ã‚’åœæ­¢"""
        self.is_monitoring = False
        if self.observer:
            self.observer.stop()
        print(f"ğŸ›‘ ç›£è¦–åœæ­¢: å‡¦ç†æ¸ˆã¿è¡Œæ•° {self.processed_lines}")


# æ–¹æ³•2: tail -f æ–¹å¼ï¼ˆLinuxãƒ©ã‚¤ã‚¯ï¼‰
class TailFollowMonitor:
    """tail -fæ–¹å¼ã§JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›£è¦–"""
    
    def __init__(self, db_path: str, task_id: str, project_id: str, spider_name: str):
        self.db_path = db_path
        self.task_id = task_id
        self.project_id = project_id
        self.spider_name = spider_name
        self.is_monitoring = False
    
    async def follow_file(self, file_path: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾ã‚’è¿½è·¡"""
        file_path = Path(file_path)
        
        print(f"ğŸ” tail -fæ–¹å¼ç›£è¦–é–‹å§‹: {file_path}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¾ã§å¾…æ©Ÿ
        while not file_path.exists() and self.is_monitoring:
            await asyncio.sleep(0.1)
        
        if not self.is_monitoring:
            return
        
        with open(file_path, 'r', encoding='utf-8') as f:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾ã«ç§»å‹•
            f.seek(0, 2)
            
            while self.is_monitoring:
                line = f.readline()
                if line:
                    line = line.strip()
                    if line:
                        await self._process_line(line)
                else:
                    await asyncio.sleep(0.1)
    
    async def _process_line(self, line: str):
        """è¡Œã‚’å‡¦ç†ã—ã¦DBã«ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ"""
        try:
            item_data = json.loads(line)
            
            # DBã‚¤ãƒ³ã‚µãƒ¼ãƒˆå‡¦ç†ï¼ˆJSONLFileMonitorã¨åŒã˜ï¼‰
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            item_id = str(uuid.uuid4())
            cursor.execute("""
                INSERT INTO scraped_items 
                (id, task_id, project_id, spider_name, data, scraped_at, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                item_id,
                self.task_id,
                self.project_id,
                self.spider_name,
                json.dumps(item_data, ensure_ascii=False),
                datetime.now().isoformat(),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… tailæ–¹å¼DBã‚¤ãƒ³ã‚µãƒ¼ãƒˆæˆåŠŸ: {item_id}")
            
        except Exception as e:
            print(f"âŒ tailæ–¹å¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def start_monitoring(self, file_path: str):
        """ç›£è¦–é–‹å§‹"""
        self.is_monitoring = True
        return asyncio.create_task(self.follow_file(file_path))
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.is_monitoring = False


# æ–¹æ³•3: éåŒæœŸãƒãƒƒãƒå‡¦ç†
class BatchJSONLProcessor:
    """ãƒãƒƒãƒå‡¦ç†ã§JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®šæœŸçš„ã«å‡¦ç†"""
    
    def __init__(self, db_path: str, task_id: str, project_id: str, spider_name: str):
        self.db_path = db_path
        self.task_id = task_id
        self.project_id = project_id
        self.spider_name = spider_name
        self.last_processed_size = 0
        self.is_processing = False
    
    async def start_batch_processing(self, file_path: str, interval: int = 5):
        """ãƒãƒƒãƒå‡¦ç†é–‹å§‹"""
        file_path = Path(file_path)
        self.is_processing = True
        
        print(f"ğŸ”„ ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {file_path} (é–“éš”: {interval}ç§’)")
        
        while self.is_processing:
            await self._process_batch(file_path)
            await asyncio.sleep(interval)
    
    async def _process_batch(self, file_path: Path):
        """ãƒãƒƒãƒã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        try:
            if not file_path.exists():
                return
            
            current_size = file_path.stat().st_size
            
            if current_size > self.last_processed_size:
                with open(file_path, 'r', encoding='utf-8') as f:
                    f.seek(self.last_processed_size)
                    new_content = f.read()
                
                new_lines = [line.strip() for line in new_content.split('\n') if line.strip()]
                
                if new_lines:
                    await self._batch_insert(new_lines)
                    print(f"ğŸ“¦ ãƒãƒƒãƒå‡¦ç†å®Œäº†: {len(new_lines)}ä»¶")
                
                self.last_processed_size = current_size
        
        except Exception as e:
            print(f"âŒ ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _batch_insert(self, lines: list):
        """è¤‡æ•°è¡Œã‚’ä¸€æ‹¬ã§DBã«ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            insert_data = []
            for line in lines:
                try:
                    item_data = json.loads(line)
                    item_id = str(uuid.uuid4())
                    insert_data.append((
                        item_id,
                        self.task_id,
                        self.project_id,
                        self.spider_name,
                        json.dumps(item_data, ensure_ascii=False),
                        datetime.now().isoformat(),
                        datetime.now().isoformat()
                    ))
                except json.JSONDecodeError:
                    continue
            
            if insert_data:
                cursor.executemany("""
                    INSERT INTO scraped_items 
                    (id, task_id, project_id, spider_name, data, scraped_at, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, insert_data)
                
                conn.commit()
                print(f"âœ… ãƒãƒƒãƒã‚¤ãƒ³ã‚µãƒ¼ãƒˆæˆåŠŸ: {len(insert_data)}ä»¶")
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ ãƒãƒƒãƒã‚¤ãƒ³ã‚µãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop_processing(self):
        """å‡¦ç†åœæ­¢"""
        self.is_processing = False


# ä½¿ç”¨ä¾‹
async def example_usage():
    """ä½¿ç”¨ä¾‹"""
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    db_path = "backend/database/scrapy_ui.db"
    
    # ã‚¿ã‚¹ã‚¯æƒ…å ±
    task_id = "test_task_123"
    project_id = "test_project"
    spider_name = "test_spider"
    jsonl_file = "scrapy_projects/test_project/results_test_task_123.jsonl"
    
    print("ğŸ¯ JSONLãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã«ã‚ˆã‚‹DBè‡ªå‹•ã‚¤ãƒ³ã‚µãƒ¼ãƒˆä¾‹")
    
    # æ–¹æ³•1: watchdogç›£è¦–
    if WATCHDOG_AVAILABLE:
        print("\nğŸ“‹ æ–¹æ³•1: watchdogç›£è¦–")
        monitor = JSONLFileMonitor(db_path, task_id, project_id, spider_name)
        # await monitor.start_monitoring(jsonl_file)
    
    # æ–¹æ³•2: tail -fæ–¹å¼
    print("\nğŸ“‹ æ–¹æ³•2: tail -fæ–¹å¼")
    tail_monitor = TailFollowMonitor(db_path, task_id, project_id, spider_name)
    # task = tail_monitor.start_monitoring(jsonl_file)
    
    # æ–¹æ³•3: ãƒãƒƒãƒå‡¦ç†
    print("\nğŸ“‹ æ–¹æ³•3: ãƒãƒƒãƒå‡¦ç†")
    batch_processor = BatchJSONLProcessor(db_path, task_id, project_id, spider_name)
    # await batch_processor.start_batch_processing(jsonl_file, interval=3)

if __name__ == "__main__":
    asyncio.run(example_usage())
