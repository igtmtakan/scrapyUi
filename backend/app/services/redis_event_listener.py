"""
Redis Event Listener Service
spider-managerã‹ã‚‰ã®Redisã‚¤ãƒ™ãƒ³ãƒˆã‚’å—ä¿¡ã—ã¦ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
"""

import asyncio
import json
import redis.asyncio as redis
from datetime import datetime, timezone
from typing import Dict, Any
import logging

from ..database import SessionLocal, Task, TaskStatus
from ..config.database_config import get_database_config

logger = logging.getLogger(__name__)


class RedisEventListener:
    """Redisã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.redis_client = None
        self.running = False
        self.subscriptions = [
            "events:spider_started",
            "events:spider_finished", 
            "events:spider_completed",
            "events:spider_progress",
            "events:results_processed"
        ]
    
    async def start(self):
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’é–‹å§‹"""
        if self.running:
            logger.warning("Redis event listener is already running")
            return
            
        try:
            # Redisæ¥ç¶šã‚’ç¢ºç«‹
            self.redis_client = redis.Redis(
                host='localhost',
                port=6379,
                decode_responses=True
            )
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            await self.redis_client.ping()
            logger.info("âœ… Redis connection established")
            
            self.running = True
            
            # ã‚¤ãƒ™ãƒ³ãƒˆè³¼èª­ã‚’é–‹å§‹
            await self._subscribe_to_events()
            
        except Exception as e:
            logger.error(f"âŒ Failed to start Redis event listener: {e}")
            raise
    
    async def stop(self):
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’åœæ­¢"""
        self.running = False
        if self.redis_client:
            await self.redis_client.close()
        logger.info("ğŸ›‘ Redis event listener stopped")
    
    async def _subscribe_to_events(self):
        """ã‚¤ãƒ™ãƒ³ãƒˆè³¼èª­å‡¦ç†"""
        try:
            pubsub = self.redis_client.pubsub()
            
            # ãƒãƒ£ãƒ³ãƒãƒ«ã‚’è³¼èª­
            for channel in self.subscriptions:
                await pubsub.subscribe(channel)
                logger.info(f"ğŸ“¡ Subscribed to channel: {channel}")
            
            logger.info("ğŸ”„ Redis event listener started")
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ãƒ«ãƒ¼ãƒ—
            async for message in pubsub.listen():
                if not self.running:
                    break
                    
                if message['type'] == 'message':
                    await self._handle_message(message['channel'], message['data'])
                    
        except Exception as e:
            logger.error(f"âŒ Error in event subscription: {e}")
        finally:
            if pubsub:
                await pubsub.close()
    
    async def _handle_message(self, channel: str, data: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†"""
        try:
            event_data = json.loads(data)
            task_id = event_data.get('task_id')
            
            if not task_id:
                logger.warning(f"âš ï¸ No task_id in event: {channel}")
                return
            
            logger.info(f"ğŸ“¥ Received event: {channel} for task {task_id[:8]}...")
            
            # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥å‡¦ç†
            if channel == "events:spider_started":
                await self._handle_spider_started(event_data)
            elif channel == "events:spider_finished":
                await self._handle_spider_finished(event_data)
            elif channel == "events:spider_completed":
                await self._handle_spider_completed(event_data)
            elif channel == "events:spider_progress":
                await self._handle_spider_progress(event_data)
            elif channel == "events:results_processed":
                await self._handle_results_processed(event_data)
                
        except Exception as e:
            logger.error(f"âŒ Error handling message from {channel}: {e}")
    
    async def _handle_spider_started(self, event_data: Dict[str, Any]):
        """ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        task_id = event_data['task_id']
        
        db = SessionLocal()
        try:
            task = db.query(Task).filter(Task.id == task_id).first()
            if task and task.status != TaskStatus.RUNNING:
                task.status = TaskStatus.RUNNING
                task.started_at = datetime.now(timezone.utc)
                db.commit()
                logger.info(f"âœ… Task {task_id[:8]}... status updated to RUNNING")
        except Exception as e:
            logger.error(f"âŒ Error updating task start status: {e}")
            db.rollback()
        finally:
            db.close()
    
    async def _handle_spider_finished(self, event_data: Dict[str, Any]):
        """ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ï¼ˆé‡è¦ï¼‰"""
        task_id = event_data['task_id']
        status = event_data.get('status', 'UNKNOWN')
        items_count = event_data.get('items_count', 0)
        return_code = event_data.get('return_code', 0)
        
        db = SessionLocal()
        try:
            task = db.query(Task).filter(Task.id == task_id).first()
            if task:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®šï¼ˆlightprogressãƒ­ã‚¸ãƒƒã‚¯ã¨çµ±ä¸€ï¼‰
                if return_code == 0 and items_count > 0:
                    # æ­£å¸¸çµ‚äº†ã‹ã¤ã‚¢ã‚¤ãƒ†ãƒ å–å¾—æ¸ˆã¿
                    task.status = TaskStatus.FINISHED
                    logger.info(f"âœ… Task {task_id[:8]}... completed successfully ({items_count} items)")
                elif return_code == 0 and items_count == 0:
                    # æ­£å¸¸çµ‚äº†ã ãŒã‚¢ã‚¤ãƒ†ãƒ ãªã— â†’ lightprogressã¨åŒã˜ãFAILEDã«è¨­å®š
                    task.status = TaskStatus.FAILED
                    task.error_count = (task.error_count or 0) + 1
                    task.error_message = "Process completed but no items were collected - marked as FAILED (redis event fix)"
                    logger.warning(f"âš ï¸ Task {task_id[:8]}... completed with no items - marked as FAILED")
                else:
                    # ç•°å¸¸çµ‚äº†
                    task.status = TaskStatus.FAILED
                    logger.warning(f"âŒ Task {task_id[:8]}... failed (return_code: {return_code})")
                
                # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
                task.items_count = items_count
                task.finished_at = datetime.now(timezone.utc)
                
                db.commit()
                logger.info(f"ğŸ”§ Task {task_id[:8]}... status updated to {task.status.value}")
                
        except Exception as e:
            logger.error(f"âŒ Error updating task finish status: {e}")
            db.rollback()
        finally:
            db.close()

    async def _handle_spider_progress(self, event_data: Dict[str, Any]):
        """ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼é€²æ—ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        task_id = event_data['task_id']
        items_processed = event_data.get('items_processed', 0)

        # é€²æ—æ›´æ–°ã¯é »ç¹ãªã®ã§ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
        if items_processed > 0:
            db = SessionLocal()
            try:
                task = db.query(Task).filter(Task.id == task_id).first()
                if task:
                    task.items_count = items_processed
                    db.commit()
            except Exception as e:
                logger.debug(f"Progress update error for {task_id}: {e}")
                db.rollback()
            finally:
                db.close()

    async def _handle_results_processed(self, event_data: Dict[str, Any]):
        """çµæœå‡¦ç†å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        task_id = event_data['task_id']
        statistics = event_data.get('statistics', {})

        db = SessionLocal()
        try:
            task = db.query(Task).filter(Task.id == task_id).first()
            if task:
                # çµ±è¨ˆæƒ…å ±ã‚’åæ˜ 
                items_count = statistics.get('items_count', task.items_count or 0)
                task.items_count = items_count

                # é‡è¤‡å‰Šé™¤æ•°ãŒã‚ã‚Œã°è¨˜éŒ²
                duplicates_removed = statistics.get('duplicates_removed', 0)
                if duplicates_removed > 0:
                    logger.info(f"ğŸ§¹ Task {task_id[:8]}... removed {duplicates_removed} duplicates")

                db.commit()
                logger.info(f"ğŸ“Š Task {task_id[:8]}... statistics updated")
        except Exception as e:
            logger.error(f"âŒ Error updating task statistics: {e}")
            db.rollback()
        finally:
            db.close()


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
redis_event_listener = RedisEventListener()
