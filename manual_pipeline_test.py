#!/usr/bin/env python3
"""
æ‰‹å‹•ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
"""
import sys
import os
from pathlib import Path
import json
import sqlite3
from datetime import datetime

# ScrapyUIã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¹ã‚’è¿½åŠ 
backend_path = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_path))

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from app.templates.database_pipeline import ScrapyUIDatabasePipeline, ScrapyUIJSONPipeline
    print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
    sys.exit(1)

# ãƒ¢ãƒƒã‚¯ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚¯ãƒ©ã‚¹
class MockSpider:
    def __init__(self, name="test_spider"):
        self.name = name
        self.logger = MockLogger()

class MockLogger:
    def info(self, msg):
        print(f"INFO: {msg}")
    
    def error(self, msg):
        print(f"ERROR: {msg}")
    
    def warning(self, msg):
        print(f"WARNING: {msg}")

def test_database_pipeline_directly():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç›´æ¥ãƒ†ã‚¹ãƒˆé–‹å§‹\n")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¿ã‚¹ã‚¯ID
    test_task_id = "test_pipeline_" + datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URL
    db_path = Path("backend/database/scrapy_ui.db")
    database_url = f"sqlite:///{db_path.absolute()}"
    
    print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆè¨­å®š:")
    print(f"  ã‚¿ã‚¹ã‚¯ID: {test_task_id}")
    print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URL: {database_url}")
    print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {db_path}")
    print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å­˜åœ¨: {db_path.exists()}")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–
    try:
        pipeline = ScrapyUIDatabasePipeline(
            database_url=database_url,
            task_id=test_task_id
        )
        print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
        return False
    
    # ãƒ¢ãƒƒã‚¯ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆ
    spider = MockSpider("test_pipeline_spider")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹å§‹
    try:
        pipeline.open_spider(spider)
        print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹å¤±æ•—: {e}")
        return False
    
    # ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†
    test_items = [
        {
            'id': 1,
            'title': 'Test Item 1',
            'description': 'This is a test item for pipeline testing',
            'url': 'https://example.com/1',
            'test_type': 'manual_pipeline_test',
            'crawl_start_datetime': datetime.now().isoformat(),
            'item_acquired_datetime': datetime.now().isoformat()
        },
        {
            'id': 2,
            'title': 'Test Item 2',
            'description': 'This is another test item for pipeline testing',
            'url': 'https://example.com/2',
            'test_type': 'manual_pipeline_test',
            'crawl_start_datetime': datetime.now().isoformat(),
            'item_acquired_datetime': datetime.now().isoformat()
        },
        {
            'id': 3,
            'title': 'Special Test Item',
            'description': 'This is a special test item with complex data',
            'url': 'https://example.com/special',
            'test_type': 'manual_pipeline_test_special',
            'complex_data': {
                'nested': True,
                'array': [1, 2, 3],
                'metadata': {'source': 'manual_test'}
            },
            'crawl_start_datetime': datetime.now().isoformat(),
            'item_acquired_datetime': datetime.now().isoformat()
        }
    ]
    
    processed_count = 0
    
    print(f"\nğŸ”„ ã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†é–‹å§‹:")
    
    for i, item in enumerate(test_items, 1):
        try:
            processed_item = pipeline.process_item(item, spider)
            print(f"  {i}. âœ… ã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†æˆåŠŸ: {item['title']}")
            processed_count += 1
        except Exception as e:
            print(f"  {i}. âŒ ã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†å¤±æ•—: {item['title']} - {e}")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’çµ‚äº†
    try:
        pipeline.close_spider(spider)
        print(f"\nâœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ‚äº†æˆåŠŸ")
        print(f"ğŸ“Š å‡¦ç†ã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ æ•°: {processed_count}ä»¶")
    except Exception as e:
        print(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ‚äº†å¤±æ•—: {e}")
        return False
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰çµæœã‚’ç¢ºèª
    return verify_pipeline_results(test_task_id, processed_count)

def verify_pipeline_results(task_id: str, expected_count: int):
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµæœã‚’æ¤œè¨¼"""
    
    print(f"\nğŸ” ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµæœæ¤œè¨¼:")
    
    db_path = Path("backend/database/scrapy_ui.db")
    
    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return False
    
    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # è©²å½“ã‚¿ã‚¹ã‚¯ã®çµæœã‚’ç¢ºèª
        cursor.execute("""
            SELECT COUNT(*) 
            FROM results 
            WHERE task_id = ?
        """, (task_id,))
        
        actual_count = cursor.fetchone()[0]
        print(f"  ğŸ“Š æœŸå¾…ä»¶æ•°: {expected_count}ä»¶")
        print(f"  ğŸ“Š å®Ÿéš›ä»¶æ•°: {actual_count}ä»¶")
        
        if actual_count == expected_count:
            print(f"  âœ… ä»¶æ•°ä¸€è‡´")
        else:
            print(f"  âŒ ä»¶æ•°ä¸ä¸€è‡´")
            return False
        
        if actual_count > 0:
            # è©³ç´°ãªçµæœã‚’ç¢ºèª
            cursor.execute("""
                SELECT id, data, crawl_start_datetime, item_acquired_datetime, created_at
                FROM results 
                WHERE task_id = ?
                ORDER BY created_at
            """, (task_id,))
            
            results = cursor.fetchall()
            
            print(f"\nğŸ“‹ ä¿å­˜ã•ã‚ŒãŸçµæœ:")
            
            success_count = 0
            
            for i, (result_id, data_json, crawl_start, item_acquired, created_at) in enumerate(results, 1):
                try:
                    data = json.loads(data_json) if isinstance(data_json, str) else data_json
                    
                    print(f"  {i}. çµæœID: {result_id}")
                    print(f"     ã‚¿ã‚¤ãƒˆãƒ«: {data.get('title', 'ä¸æ˜')}")
                    print(f"     ãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ—: {data.get('test_type', 'ä¸æ˜')}")
                    print(f"     ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆ: {crawl_start}")
                    print(f"     ã‚¢ã‚¤ãƒ†ãƒ å–å¾—: {item_acquired}")
                    print(f"     ä½œæˆæ—¥æ™‚: {created_at}")
                    
                    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                    if (data.get('title') and 
                        data.get('test_type') and 
                        crawl_start and 
                        item_acquired):
                        print(f"     âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§: æ­£å¸¸")
                        success_count += 1
                    else:
                        print(f"     âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§: å•é¡Œã‚ã‚Š")
                    
                    print(f"     ---")
                    
                except Exception as e:
                    print(f"     âŒ ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
            
            print(f"\nğŸ“Š æ¤œè¨¼çµæœ:")
            print(f"  ç·ä»¶æ•°: {actual_count}ä»¶")
            print(f"  æˆåŠŸä»¶æ•°: {success_count}ä»¶")
            print(f"  æˆåŠŸç‡: {success_count/actual_count*100:.1f}%")
            
            return success_count == actual_count
        else:
            print("âš ï¸ ä¿å­˜ã•ã‚ŒãŸçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    finally:
        if 'conn' in locals():
            conn.close()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¯ æ‰‹å‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ãƒ†ã‚¹ãƒˆ\n")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
    success = test_database_pipeline_directly()
    
    print("\nğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
    
    if success:
        print("\nâœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
        print("\nğŸ”§ ç¢ºèªäº‹é …:")
        print("  âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒæ­£å¸¸ã«å‹•ä½œ")
        print("  âœ… ã‚¢ã‚¤ãƒ†ãƒ ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ­£ã—ãä¿å­˜")
        print("  âœ… æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ­£ã—ãè¨­å®š")
        print("  âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãŒä¿ãŸã‚Œã¦ã„ã‚‹")
    else:
        print("\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ãƒ†ã‚¹ãƒˆå¤±æ•—")
        print("\nğŸ”§ ç¢ºèªãŒå¿…è¦ãªé …ç›®:")
        print("  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š")
        print("  - ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š")
        print("  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ")
        print("  - æ¨©é™è¨­å®š")

if __name__ == "__main__":
    main()
