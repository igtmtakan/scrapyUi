"""
ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹
åŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç›£è¦–ã¨è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½
"""

import asyncio
import json
import logging
import psutil
import redis.asyncio as redis
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from sqlalchemy.orm import Session
from ..database import SessionLocal, Task, TaskStatus

logger = logging.getLogger(__name__)

class SystemHealthMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°"""
    
    def __init__(self):
        self.running = False
        self.redis_client = None
        self.base_projects_dir = Path("/home/igtmtakan/workplace/python/scrapyUI/scrapy_projects")
        self.health_stats = {
            'last_check': None,
            'system_status': 'unknown',
            'issues_detected': [],
            'auto_repairs': 0,
            'performance_metrics': {}
        }
        
    async def initialize(self):
        """åˆæœŸåŒ–"""
        try:
            # Redisæ¥ç¶š
            self.redis_client = redis.Redis(
                host='localhost',
                port=6379,
                decode_responses=True
            )
            await self.redis_client.ping()
            logger.info("âœ… Redis connection established for health monitor")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Redis connection failed for health monitor: {e}")
            self.redis_client = None

    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        self.running = True
        logger.info("ğŸ” System health monitoring started")
        
        # å®šæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        asyncio.create_task(self._health_check_loop())
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        asyncio.create_task(self._performance_monitor_loop())
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        asyncio.create_task(self._data_integrity_check_loop())

    async def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.running = False
        if self.redis_client:
            await self.redis_client.close()
        logger.info("ğŸ›‘ System health monitoring stopped")

    async def _health_check_loop(self):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                await self._perform_health_check()
                await asyncio.sleep(60)  # 1åˆ†é–“éš”
            except Exception as e:
                logger.error(f"âŒ Health check error: {e}")
                await asyncio.sleep(30)

    async def _performance_monitor_loop(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                await self._collect_performance_metrics()
                await asyncio.sleep(300)  # 5åˆ†é–“éš”
            except Exception as e:
                logger.error(f"âŒ Performance monitoring error: {e}")
                await asyncio.sleep(60)

    async def _data_integrity_check_loop(self):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                await self._check_data_integrity()
                await asyncio.sleep(1800)  # 30åˆ†é–“éš”
            except Exception as e:
                logger.error(f"âŒ Data integrity check error: {e}")
                await asyncio.sleep(300)

    async def _perform_health_check(self):
        """åŒ…æ‹¬çš„ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        self.health_stats['last_check'] = datetime.now()
        issues = []
        
        # 1. ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        if cpu_percent > 80:
            issues.append(f"High CPU usage: {cpu_percent}%")
        
        if memory.percent > 85:
            issues.append(f"High memory usage: {memory.percent}%")
        
        if disk.percent > 90:
            issues.append(f"High disk usage: {disk.percent}%")
        
        # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
        try:
            with SessionLocal() as db:
                db.execute("SELECT 1")
        except Exception as e:
            issues.append(f"Database connection failed: {e}")
        
        # 3. Redisæ¥ç¶šãƒã‚§ãƒƒã‚¯
        if self.redis_client:
            try:
                await self.redis_client.ping()
            except Exception as e:
                issues.append(f"Redis connection failed: {e}")
        
        # 4. ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ãƒã‚§ãƒƒã‚¯
        services_status = await self._check_microservices()
        for service, status in services_status.items():
            if not status:
                issues.append(f"Microservice {service} is down")
        
        # 5. é•·æ™‚é–“å®Ÿè¡Œã‚¿ã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
        stuck_tasks = await self._check_stuck_tasks()
        if stuck_tasks:
            issues.append(f"Found {len(stuck_tasks)} stuck tasks")
            await self._auto_repair_stuck_tasks(stuck_tasks)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
        self.health_stats['issues_detected'] = issues
        self.health_stats['system_status'] = 'healthy' if not issues else 'warning'
        
        # Redis ã«çŠ¶æ…‹ã‚’ä¿å­˜
        if self.redis_client:
            await self.redis_client.setex(
                "system:health_status",
                300,  # 5åˆ†é–“æœ‰åŠ¹
                json.dumps(self.health_stats, default=str)
            )
        
        if issues:
            logger.warning(f"âš ï¸ Health issues detected: {len(issues)}")
            for issue in issues:
                logger.warning(f"  - {issue}")
        else:
            logger.debug("âœ… System health check passed")

    async def _collect_performance_metrics(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        metrics = {
            'timestamp': datetime.now(),
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'active_connections': len(psutil.net_connections()),
            'process_count': len(psutil.pids())
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        try:
            with SessionLocal() as db:
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¹ã‚¯æ•°
                active_tasks = db.query(Task).filter(
                    Task.status == TaskStatus.RUNNING
                ).count()
                
                # æœ€è¿‘1æ™‚é–“ã®å®Œäº†ã‚¿ã‚¹ã‚¯æ•°
                recent_completed = db.query(Task).filter(
                    Task.status == TaskStatus.FINISHED,
                    Task.finished_at >= datetime.now() - timedelta(hours=1)
                ).count()
                
                metrics.update({
                    'active_tasks': active_tasks,
                    'recent_completed_tasks': recent_completed
                })
                
        except Exception as e:
            logger.error(f"âŒ Database metrics collection failed: {e}")
        
        self.health_stats['performance_metrics'] = metrics
        
        # Redis ã«ä¿å­˜
        if self.redis_client:
            await self.redis_client.lpush(
                "system:performance_history",
                json.dumps(metrics, default=str)
            )
            # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
            await self.redis_client.ltrim("system:performance_history", 0, 99)

    async def _check_data_integrity(self):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            with SessionLocal() as db:
                # ã‚¢ã‚¤ãƒ†ãƒ æ•°ãŒ0ã®FINISHEDã‚¿ã‚¹ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
                zero_item_tasks = db.query(Task).filter(
                    Task.status == TaskStatus.FINISHED,
                    Task.items_count == 0
                ).limit(10).all()
                
                for task in zero_item_tasks:
                    # å¯¾å¿œã™ã‚‹çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                    result_file = self.base_projects_dir / f"*/results_{task.id}.jsonl"
                    result_files = list(self.base_projects_dir.glob(f"*/results_{task.id}.jsonl"))
                    
                    if result_files:
                        file_path = result_files[0]
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                actual_count = sum(1 for line in f if line.strip())
                            
                            if actual_count > 0:
                                # è‡ªå‹•ä¿®å¾©
                                task.items_count = actual_count
                                db.commit()
                                self.health_stats['auto_repairs'] += 1
                                logger.info(f"ğŸ”§ Auto-repaired task {task.id}: 0 â†’ {actual_count} items")
                                
                        except Exception as e:
                            logger.error(f"âŒ File check failed for {task.id}: {e}")
                
        except Exception as e:
            logger.error(f"âŒ Data integrity check failed: {e}")

    async def _check_microservices(self) -> Dict[str, bool]:
        """ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯"""
        services = {
            'spider_manager': 'http://localhost:8002/health',
            'test_service': 'http://localhost:8005/health'
        }
        
        status = {}
        for service, url in services.items():
            try:
                import aiohttp
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=5) as response:
                        status[service] = response.status == 200
            except Exception:
                status[service] = False
        
        return status

    async def _check_stuck_tasks(self) -> List[str]:
        """ã‚¹ã‚¿ãƒƒã‚¯ã—ãŸã‚¿ã‚¹ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            with SessionLocal() as db:
                # 1æ™‚é–“ä»¥ä¸ŠRUNNINGã®ã‚¿ã‚¹ã‚¯
                stuck_threshold = datetime.now() - timedelta(hours=1)
                stuck_tasks = db.query(Task).filter(
                    Task.status == TaskStatus.RUNNING,
                    Task.started_at < stuck_threshold
                ).all()
                
                return [task.id for task in stuck_tasks]
                
        except Exception as e:
            logger.error(f"âŒ Stuck task check failed: {e}")
            return []

    async def _auto_repair_stuck_tasks(self, task_ids: List[str]):
        """ã‚¹ã‚¿ãƒƒã‚¯ã—ãŸã‚¿ã‚¹ã‚¯ã®è‡ªå‹•ä¿®å¾©"""
        try:
            with SessionLocal() as db:
                for task_id in task_ids:
                    task = db.query(Task).filter(Task.id == task_id).first()
                    if task:
                        # ã‚¿ã‚¹ã‚¯ã‚’FAILEDã«å¤‰æ›´
                        task.status = TaskStatus.FAILED
                        task.finished_at = datetime.now()
                        self.health_stats['auto_repairs'] += 1
                        logger.info(f"ğŸ”§ Auto-repaired stuck task: {task_id}")
                
                db.commit()
                
        except Exception as e:
            logger.error(f"âŒ Auto-repair failed: {e}")

    async def get_health_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹ã‚’å–å¾—"""
        return self.health_stats.copy()

    async def get_performance_history(self) -> List[Dict]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´ã‚’å–å¾—"""
        if not self.redis_client:
            return []
        
        try:
            history = await self.redis_client.lrange("system:performance_history", 0, -1)
            return [json.loads(item) for item in history]
        except Exception as e:
            logger.error(f"âŒ Performance history retrieval failed: {e}")
            return []

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
system_health_monitor = SystemHealthMonitor()
