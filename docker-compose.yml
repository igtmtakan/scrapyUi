version: '3.8'

services:
  # FastAPI Backend
  backend:
    build: .
    container_name: scrapyui-backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=sqlite:///./data/scrapyui.db
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-here}
      - NODEJS_SERVICE_URL=http://nodejs:3001
      - ENVIRONMENT=production
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./uploads:/app/uploads
      - ./exports:/app/exports
    depends_on:
      - nodejs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Node.js Puppeteer Service
  nodejs:
    build: .
    container_name: scrapyui-nodejs
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - HOST=0.0.0.0
      - API_KEY=${NODEJS_API_KEY:-}
      - BROWSER_POOL_SIZE=3
      - BROWSER_TIMEOUT=30000
    volumes:
      - ./logs:/app/logs
      - ./exports:/app/exports
    restart: unless-stopped
    command: ["node", "nodejs-service/src/app.js"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Security options for Puppeteer
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_ADMIN

  # Next.js Frontend (optional, for development)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: scrapyui-frontend
    ports:
      - "4000:4000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_NODEJS_URL=http://localhost:3001
    depends_on:
      - backend
    restart: unless-stopped
    profiles:
      - frontend

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: scrapyui-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    profiles:
      - cache

  # PostgreSQL database (optional, alternative to SQLite)
  postgres:
    image: postgres:15-alpine
    container_name: scrapyui-postgres
    environment:
      - POSTGRES_DB=scrapyui
      - POSTGRES_USER=scrapyui
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-scrapyui123}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    profiles:
      - postgres

  # Prometheus for monitoring (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: scrapyui-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    profiles:
      - monitoring

  # Grafana for visualization (optional)
  grafana:
    image: grafana/grafana:latest
    container_name: scrapyui-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring

  # Nginx reverse proxy (optional)
  nginx:
    image: nginx:alpine
    container_name: scrapyui-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend
    restart: unless-stopped
    profiles:
      - proxy

volumes:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:

networks:
  default:
    name: scrapyui-network
