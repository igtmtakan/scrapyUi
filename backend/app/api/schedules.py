from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
import uuid
from datetime import datetime
from croniter import croniter
from pydantic import BaseModel

from ..database import get_db, Schedule as DBSchedule, Project as DBProject, Spider as DBSpider, Task as DBTask, Result as DBResult, User as DBUser, UserRole, TaskStatus
from ..models.schemas import Schedule, ScheduleCreate, ScheduleUpdate
# Celeryå»ƒæ­¢æ¸ˆã¿ - ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å¯¾å¿œ
# from ..tasks.scrapy_tasks import scheduled_spider_run
from ..services.scheduler_service import scheduler_service
from ..services.realtime_websocket_manager import realtime_websocket_manager
from .auth import get_current_active_user
import asyncio

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
class ResetTasksRequest(BaseModel):
    hours_back: int = 24
    cleanup_orphaned: bool = True
    reset_all: bool = False

router = APIRouter(
    responses={
        404: {"description": "Not found"},
        400: {"description": "Bad request"},
        500: {"description": "Internal server error"}
    }
)

@router.get(
    "/",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§å–å¾—",
    description="ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚",
    response_description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ"
)
async def get_schedules(
    project_id: str = None,
    is_active: bool = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_active_user)
):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§å–å¾—

    ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **project_id** (optional): ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    - **is_active** (optional): ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    # JOINã‚¯ã‚¨ãƒªã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æƒ…å ±ã‚’å«ã‚ã‚‹
    query = db.query(
        DBSchedule,
        DBProject.name.label('project_name'),
        DBSpider.name.label('spider_name')
    ).join(
        DBProject, DBSchedule.project_id == DBProject.id
    ).join(
        DBSpider, DBSchedule.spider_id == DBSpider.id
    )

    # ç®¡ç†è€…ã¯å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿
    is_admin = (current_user.role == UserRole.ADMIN or
                current_user.role == "ADMIN" or
                current_user.role == "admin")
    if not is_admin:
        query = query.filter(DBProject.user_id == current_user.id)

    if project_id:
        query = query.filter(DBSchedule.project_id == project_id)
    if is_active is not None:
        query = query.filter(DBSchedule.is_active == is_active)

    results = query.order_by(DBSchedule.created_at.desc()).all()

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’èª¿æ•´
    schedules = []
    for schedule, project_name, spider_name in results:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã«ã‚ˆã‚‹æœ€æ–°ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—ï¼ˆå®Ÿè¡Œä¸­ã‚’å„ªå…ˆï¼‰
        # ã¾ãšå®Ÿè¡Œä¸­ãƒ»å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯ã‚’ç¢ºèªï¼ˆCelery Workerã®å®Ÿéš›ã®çŠ¶æ…‹ã‚‚è€ƒæ…®ï¼‰
        active_task = db.query(DBTask).filter(
            DBTask.project_id == schedule.project_id,
            DBTask.spider_id == schedule.spider_id,
            DBTask.schedule_id == schedule.id,  # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®ã‚¿ã‚¹ã‚¯ã®ã¿
            DBTask.status.in_(['RUNNING', 'PENDING'])
        ).order_by(DBTask.created_at.desc()).first()

        # ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å¯¾å¿œ: å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ç¢ºèª
        if active_task:
            try:
                from ..services.microservice_client import microservice_client

                # ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                if not microservice_client.is_microservice_available():
                    print(f"âš ï¸ Microservice not available. Marking task {active_task.id} as failed.")
                    try:
                        active_task.status = 'FAILED'
                        active_task.finished_at = datetime.now()
                        db.commit()
                        active_task = None  # å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ã¨ã—ã¦æ‰±ã‚ãªã„
                    except Exception as db_error:
                        print(f"âš ï¸ Database error when updating task status: {db_error}")
                        db.rollback()
                        active_task = None

            except Exception as e:
                print(f"âš ï¸ Error checking microservice status: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å®‰å…¨å´ã«å€’ã—ã¦ã€å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ã¨ã—ã¦æ‰±ã‚ãªã„
                if active_task:
                    try:
                        active_task.status = 'FAILED'
                        active_task.finished_at = datetime.now()
                        db.commit()
                        active_task = None
                    except Exception as db_error:
                        print(f"âš ï¸ Database error when updating task status: {db_error}")
                        db.rollback()
                        active_task = None

        # å®Ÿè¡Œä¸­ãƒ»å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°æœ€æ–°ã®å®Œäº†ã‚¿ã‚¹ã‚¯
        if active_task:
            latest_task = active_task
        else:
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®ã‚¿ã‚¹ã‚¯ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°æ‰‹å‹•å®Ÿè¡Œã‚‚å«ã‚ã‚‹
            latest_task = db.query(DBTask).filter(
                DBTask.project_id == schedule.project_id,
                DBTask.spider_id == schedule.spider_id,
                DBTask.schedule_id == schedule.id  # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®ã‚¿ã‚¹ã‚¯ã®ã¿
            ).order_by(DBTask.created_at.desc()).first()

            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®ã‚¿ã‚¹ã‚¯ãŒãªã„å ´åˆã¯ã€æ‰‹å‹•å®Ÿè¡Œã‚‚å«ã‚ã¦æœ€æ–°ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            if not latest_task:
                latest_task = db.query(DBTask).filter(
                    DBTask.project_id == schedule.project_id,
                    DBTask.spider_id == schedule.spider_id
                ).order_by(DBTask.created_at.desc()).first()

        # Cronå¼ã‹ã‚‰é–“éš”ï¼ˆåˆ†ï¼‰ã‚’æ¨å®š
        interval_minutes = None
        try:
            # ç°¡æ˜“çš„ãªé–“éš”è¨ˆç®—ï¼ˆã‚ˆã‚Šæ­£ç¢ºãªå®Ÿè£…ãŒå¿…è¦ãªå ´åˆã¯æ”¹å–„ï¼‰
            if schedule.cron_expression.startswith("*/"):
                # */7 * * * * å½¢å¼
                parts = schedule.cron_expression.split()
                if len(parts) >= 1 and parts[0].startswith("*/"):
                    interval_minutes = int(parts[0][2:])
            elif " " in schedule.cron_expression:
                # 0 */2 * * * å½¢å¼ï¼ˆæ™‚é–“é–“éš”ï¼‰
                parts = schedule.cron_expression.split()
                if len(parts) >= 2 and parts[1].startswith("*/"):
                    interval_minutes = int(parts[1][2:]) * 60
        except:
            pass

        # æœ€æ–°ã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’å«ã‚ã‚‹
        latest_task_dict = None
        if latest_task:
            # Rich progressã¨åŒã˜æ–¹æ³•ã§å…¨çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            from ..services.scrapy_service import ScrapyPlaywrightService
            scrapy_service = ScrapyPlaywrightService()

            # Scrapyã®çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            full_stats = scrapy_service._get_scrapy_full_stats(latest_task.id, latest_task.project_id)

            # å®Ÿéš›ã®DBçµæœæ•°ã‚’ç¢ºèªã—ã¦ã‚¿ã‚¹ã‚¯ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’åŒæœŸ
            actual_db_count = db.query(DBResult).filter(DBResult.task_id == latest_task.id).count()

            # ã‚¿ã‚¹ã‚¯ã®ã‚¢ã‚¤ãƒ†ãƒ æ•°ãŒå®Ÿéš›ã®DBçµæœæ•°ã¨ç•°ãªã‚‹å ´åˆã¯åŒæœŸ
            if latest_task.items_count != actual_db_count and actual_db_count > 0:
                print(f"ğŸ”§ Syncing task {latest_task.id[:8]}... items count: {latest_task.items_count} â†’ {actual_db_count}")
                latest_task.items_count = actual_db_count
                latest_task.requests_count = max(actual_db_count, latest_task.requests_count or 1)
                db.commit()

            # åŸºæœ¬çµ±è¨ˆæƒ…å ±ï¼ˆå„ªå…ˆé †ä½ï¼šRichçµ±è¨ˆ > å®Ÿéš›ã®DBçµæœæ•° > ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å€¤ > 0ï¼‰
            # Rich progress extensionã®çµ±è¨ˆæƒ…å ±ã‚’æœ€å„ªå…ˆ
            final_items = full_stats.get('items_count', 0) if full_stats and full_stats.get('items_count', 0) > 0 else (actual_db_count if actual_db_count > 0 else (latest_task.items_count or 0))
            final_requests = full_stats.get('requests_count', 0) if full_stats and full_stats.get('requests_count', 0) > 0 else (max(actual_db_count, latest_task.requests_count or 0) if actual_db_count > 0 else (latest_task.requests_count or 0))
            final_responses = full_stats.get('responses_count', 0) if full_stats else 0
            final_errors = (latest_task.error_count or 0) if (latest_task.error_count or 0) >= 0 else (full_stats.get('errors_count', 0) if full_stats else 0)

            # Scrapyã®å®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆç‹¬è‡ªåˆ¤å®šã‚’å‰Šé™¤ï¼‰
            actual_status = latest_task.status.value if hasattr(latest_task.status, 'value') else latest_task.status

            latest_task_dict = {
                "id": latest_task.id,
                "status": actual_status,  # Scrapyã®å®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä½¿ç”¨
                "items_count": final_items,
                "requests_count": final_requests,
                "responses_count": final_responses,
                "error_count": final_errors,
                "started_at": latest_task.started_at,
                "finished_at": latest_task.finished_at,
                "created_at": latest_task.created_at,
                "rich_stats": full_stats,
                "scrapy_stats_used": bool(full_stats)
            }

        schedule_dict = {
            "id": schedule.id,
            "name": schedule.name,
            "description": schedule.description,
            "cron_expression": schedule.cron_expression,
            "interval_minutes": interval_minutes,
            "project_id": schedule.project_id,
            "spider_id": schedule.spider_id,
            "is_active": schedule.is_active,
            "last_run": schedule.last_run,
            "next_run": schedule.next_run,
            "created_at": schedule.created_at,
            "updated_at": schedule.updated_at,
            "settings": schedule.settings,
            "project_name": project_name,
            "spider_name": spider_name,
            "latest_task": latest_task_dict
        }
        schedules.append(schedule_dict)

    return schedules

@router.get(
    "/{schedule_id}",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°å–å¾—",
    description="æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚",
    response_description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±"
)
async def get_schedule(schedule_id: str, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°å–å¾—

    æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°æƒ…å ±ã‚’è¿”ã—ã¾ã™
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    # JOINã‚¯ã‚¨ãƒªã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æƒ…å ±ã‚’å«ã‚ã‚‹
    result = db.query(
        DBSchedule,
        DBProject.name.label('project_name'),
        DBSpider.name.label('spider_name')
    ).join(
        DBProject, DBSchedule.project_id == DBProject.id
    ).join(
        DBSpider, DBSchedule.spider_id == DBSpider.id
    ).filter(DBSchedule.id == schedule_id).first()

    if not result:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    schedule, project_name, spider_name = result

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’èª¿æ•´
    schedule_dict = {
        "id": schedule.id,
        "name": schedule.name,
        "description": schedule.description,
        "cron_expression": schedule.cron_expression,
        "project_id": schedule.project_id,
        "spider_id": schedule.spider_id,
        "is_active": schedule.is_active,
        "last_run": schedule.last_run,
        "next_run": schedule.next_run,
        "created_at": schedule.created_at,
        "updated_at": schedule.updated_at,
        "settings": schedule.settings,
        "project_name": project_name,
        "spider_name": spider_name
    }

    return schedule_dict

@router.post(
    "/",
    status_code=status.HTTP_201_CREATED,
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ",
    description="æ–°ã—ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚",
    response_description="ä½œæˆã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æƒ…å ±"
)
async def create_schedule(schedule: ScheduleCreate, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ

    æ–°ã—ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

    ### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    - **name**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
    - **description** (optional): ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª¬æ˜
    - **cron_expression**: Cronå¼ï¼ˆä¾‹: "0 2 * * *" = æ¯æ—¥åˆå‰2æ™‚ï¼‰
    - **project_id**: å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ID
    - **spider_id**: å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®ID
    - **is_active** (optional): ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰
    - **settings** (optional): å®Ÿè¡Œæ™‚ã®è¨­å®š

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **201**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«ä½œæˆã•ã‚ŒãŸå ´åˆ
    - **400**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
    - **404**: æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¾ãŸã¯ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
    project = db.query(DBProject).filter(DBProject.id == schedule.project_id).first()
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found"
        )

    spider = db.query(DBSpider).filter(DBSpider.id == schedule.spider_id).first()
    if not spider:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Spider not found"
        )

    # Cronå¼ã®è©³ç´°æ¤œè¨¼
    try:
        # åŸºæœ¬çš„ãªCronå¼æ¤œè¨¼
        cron = croniter(schedule.cron_expression, datetime.now())
        next_run = cron.get_next(datetime)

        # è¿½åŠ ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        cron_parts = schedule.cron_expression.split()
        if len(cron_parts) != 5:
            raise ValueError("Cron expression must have exactly 5 parts")

        # åˆ†ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ0-59ï¼‰
        minute_part = cron_parts[0]
        if minute_part != '*' and not minute_part.startswith('*/'):
            try:
                minute_val = int(minute_part)
                if minute_val < 0 or minute_val > 59:
                    raise ValueError("Minute must be between 0-59")
            except ValueError:
                pass  # è¤‡é›‘ãªå¼ã¯ croniter ã«ä»»ã›ã‚‹

        # æ™‚é–“ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ0-23ï¼‰
        hour_part = cron_parts[1]
        if hour_part != '*' and not hour_part.startswith('*/'):
            try:
                hour_val = int(hour_part)
                if hour_val < 0 or hour_val > 23:
                    raise ValueError("Hour must be between 0-23")
            except ValueError:
                pass

        # å®Ÿè¡Œé »åº¦ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ1åˆ†æœªæº€ã®å®Ÿè¡Œã‚’é˜²æ­¢ï¼‰
        if minute_part.startswith('*/'):
            interval = int(minute_part[2:])
            if interval == 0:
                raise ValueError("Execution interval cannot be 0")

        # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ãŒå¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
        if next_run <= datetime.now():
            # 1ç§’å¾Œã®æ™‚åˆ»ã§å†è¨ˆç®—
            future_time = datetime.now().replace(second=0, microsecond=0)
            cron = croniter(schedule.cron_expression, future_time)
            next_run = cron.get_next(datetime)

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Invalid cron expression: {str(e)}"
        )

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    existing_schedule = db.query(DBSchedule).filter(
        DBSchedule.name == schedule.name,
        DBSchedule.project_id == schedule.project_id
    ).first()
    if existing_schedule:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Schedule with this name already exists in the project"
        )

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    db_schedule = DBSchedule(
        id=str(uuid.uuid4()),
        name=schedule.name,
        description=schedule.description,
        cron_expression=schedule.cron_expression,
        project_id=schedule.project_id,
        spider_id=schedule.spider_id,
        is_active=schedule.is_active,
        next_run=next_run,
        settings=schedule.settings
    )

    db.add(db_schedule)
    db.commit()
    db.refresh(db_schedule)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’å«ã‚ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    schedule_dict = {
        "id": db_schedule.id,
        "name": db_schedule.name,
        "description": db_schedule.description,
        "cron_expression": db_schedule.cron_expression,
        "project_id": db_schedule.project_id,
        "spider_id": db_schedule.spider_id,
        "is_active": db_schedule.is_active,
        "last_run": db_schedule.last_run,
        "next_run": db_schedule.next_run,
        "created_at": db_schedule.created_at,
        "updated_at": db_schedule.updated_at,
        "settings": db_schedule.settings,
        "project_name": project.name if project else "N/A",
        "spider_name": spider.name if spider else "N/A"
    }

    return schedule_dict

@router.put(
    "/{schedule_id}",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°",
    description="æ—¢å­˜ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚",
    response_description="æ›´æ–°ã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æƒ…å ±"
)
async def update_schedule(
    schedule_id: str,
    schedule_update: ScheduleUpdate,
    db: Session = Depends(get_db)
):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°

    æ—¢å­˜ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: æ›´æ–°ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    - **name** (optional): ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
    - **description** (optional): ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª¬æ˜
    - **cron_expression** (optional): Cronå¼
    - **is_active** (optional): ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹
    - **settings** (optional): å®Ÿè¡Œæ™‚ã®è¨­å®š

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«æ›´æ–°ã•ã‚ŒãŸå ´åˆ
    - **400**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    # æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã®é©ç”¨
    update_data = schedule_update.model_dump(exclude_unset=True)

    # Cronå¼ãŒæ›´æ–°ã•ã‚Œã‚‹å ´åˆã¯æ¤œè¨¼
    if 'cron_expression' in update_data:
        try:
            cron = croniter(update_data['cron_expression'], datetime.now())
            next_run = cron.get_next(datetime)
            update_data['next_run'] = next_run
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Invalid cron expression: {str(e)}"
            )

    for field, value in update_data.items():
        setattr(db_schedule, field, value)

    db.commit()
    db.refresh(db_schedule)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’å–å¾—
    project = db.query(DBProject).filter(DBProject.id == db_schedule.project_id).first()
    spider = db.query(DBSpider).filter(DBSpider.id == db_schedule.spider_id).first()

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’å«ã‚ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    schedule_dict = {
        "id": db_schedule.id,
        "name": db_schedule.name,
        "description": db_schedule.description,
        "cron_expression": db_schedule.cron_expression,
        "project_id": db_schedule.project_id,
        "spider_id": db_schedule.spider_id,
        "is_active": db_schedule.is_active,
        "last_run": db_schedule.last_run,
        "next_run": db_schedule.next_run,
        "created_at": db_schedule.created_at,
        "updated_at": db_schedule.updated_at,
        "settings": db_schedule.settings,
        "project_name": project.name if project else "N/A",
        "spider_name": spider.name if spider else "N/A"
    }

    return schedule_dict

@router.delete(
    "/{schedule_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å‰Šé™¤",
    description="æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚é–¢é€£ã™ã‚‹å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚‚å‰Šé™¤ã•ã‚Œã¾ã™ã€‚"
)
async def delete_schedule(schedule_id: str, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å‰Šé™¤

    æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚é–¢é€£ã™ã‚‹å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚‚å‰Šé™¤ã•ã‚Œã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: å‰Šé™¤ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **204**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚ŒãŸå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    try:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«é–¢é€£ã™ã‚‹å¾…æ©Ÿä¸­ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤
        related_pending_tasks = db.query(DBTask).filter(
            DBTask.project_id == db_schedule.project_id,
            DBTask.spider_id == db_schedule.spider_id,
            DBTask.status == TaskStatus.PENDING
        ).all()

        deleted_tasks_count = 0
        if related_pending_tasks:
            print(f"ğŸ—‘ï¸ Deleting {len(related_pending_tasks)} pending tasks related to schedule {db_schedule.name}")
            for task in related_pending_tasks:
                print(f"  - Deleting pending task: {task.id[:8]}... (created: {task.created_at})")
                db.delete(task)
                deleted_tasks_count += 1

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è‡ªä½“ã‚’å‰Šé™¤
        print(f"ğŸ—‘ï¸ Deleting schedule: {db_schedule.name} (ID: {db_schedule.id})")
        db.delete(db_schedule)

        # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
        db.commit()

        print(f"âœ… Successfully deleted schedule and {deleted_tasks_count} related pending tasks")

    except Exception as e:
        print(f"âš ï¸ Error deleting schedule and related tasks: {str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete schedule and related tasks: {str(e)}"
        )

    return None

@router.post(
    "/{schedule_id}/run",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ‰‹å‹•å®Ÿè¡Œ",
    description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ‰‹å‹•ã§å®Ÿè¡Œã—ã¾ã™ã€‚"
)
async def run_schedule_now(schedule_id: str, db: Session = Depends(get_db), current_user = Depends(get_current_active_user)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ‰‹å‹•å®Ÿè¡Œ

    ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ‰‹å‹•ã§å®Ÿè¡Œã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: å®Ÿè¡Œã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«é–‹å§‹ã•ã‚ŒãŸå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **400**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    if not db_schedule.is_active:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Schedule is not active"
        )

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
    project = db.query(DBProject).filter(DBProject.id == db_schedule.project_id).first()
    spider = db.query(DBSpider).filter(DBSpider.id == db_schedule.spider_id).first()

    if not project or not spider:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project or Spider not found"
        )

    # å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¤‡å®Ÿè¡Œé˜²æ­¢ï¼‰
    running_tasks = db.query(DBTask).filter(
        DBTask.project_id == db_schedule.project_id,
        DBTask.spider_id == db_schedule.spider_id,
        DBTask.status.in_([TaskStatus.RUNNING, TaskStatus.PENDING])
    ).all()

    if running_tasks:
        running_task_info = []
        for task in running_tasks:
            elapsed = (datetime.now() - task.started_at).total_seconds() if task.started_at else 0
            running_task_info.append(f"Task {task.id[:8]}... (running for {elapsed:.0f}s)")

        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Cannot execute schedule: {len(running_tasks)} task(s) already running. {', '.join(running_task_info)}"
        )

    # ã‚¿ã‚¹ã‚¯IDã‚’ç”Ÿæˆ
    import uuid
    task_id = str(uuid.uuid4())

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
    db_task = DBTask(
        id=task_id,
        spider_id=spider.id,
        project_id=project.id,
        user_id=current_user.id,
        status=TaskStatus.PENDING,
        settings=db_schedule.settings or {},
        created_at=datetime.now()
    )
    db.add(db_task)

    # ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹çµŒç”±ã§watchdogå®Ÿè¡Œã‚’é–‹å§‹
    import os
    if not os.getenv("TESTING", False):
        from ..services.microservice_client import microservice_client

        # ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        if microservice_client.is_microservice_available():
            try:
                # ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹çµŒç”±ã§å®Ÿè¡Œ
                result = microservice_client.execute_spider_with_watchdog_sync(
                    project_id=str(project.id),
                    spider_id=str(spider.id),
                    project_path=project.path,
                    spider_name=spider.name,
                    task_id=task_id,
                    settings=db_schedule.settings or {}
                )

                if result["success"]:
                    print(f"ğŸš€ Microservice execution started for task: {task_id}")
                    print(f"   Project: {project.name}")
                    print(f"   Spider: {spider.name}")
                    print(f"   Task ID: {task_id}")
                else:
                    print(f"âŒ Microservice execution failed: {result.get('error')}")
                    raise Exception(f"Microservice execution failed: {result.get('error')}")

            except Exception as e:
                print(f"âŒ Failed to start microservice task for manual execution: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥å®Ÿè¡Œ
                from ..services.scrapy_service import ScrapyPlaywrightService
                scrapy_service = ScrapyPlaywrightService()

                # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿè¡Œã‚’é–‹å§‹
                import threading
                def run_spider_background():
                    try:
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)

                        # WebSocketã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
                        def websocket_callback(data: dict):
                            try:
                                from ..api.websocket_progress import broadcast_rich_progress_update
                                asyncio.create_task(broadcast_rich_progress_update(task_id, data))
                            except Exception as e:
                                print(f"âš ï¸ WebSocket callback error in schedule run: {e}")

                        # watchdogç›£è¦–ä»˜ãã§å®Ÿè¡Œ
                        result = loop.run_until_complete(
                            scrapy_service.run_spider_with_watchdog(
                                project_path=project.path,
                                spider_name=spider.name,
                                task_id=task_id,
                                settings=db_schedule.settings or {},
                                websocket_callback=websocket_callback
                            )
                        )
                        print(f"âœ… Fallback spider execution completed: {result}")
                    except Exception as e:
                        print(f"âŒ Fallback spider execution error: {e}")
                    finally:
                        loop.close()

                thread = threading.Thread(target=run_spider_background, daemon=True)
                thread.start()
                print(f"ğŸ”„ Fallback execution started for task: {task_id}")
        else:
            print("âš ï¸ Microservice not available, using legacy execution")
            # å¾“æ¥ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚’ä½¿ç”¨
            from ..services.scrapy_service import ScrapyPlaywrightService
            scrapy_service = ScrapyPlaywrightService()

            import threading
            def run_spider_background():
                try:
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    def websocket_callback(data: dict):
                        try:
                            from ..api.websocket_progress import broadcast_rich_progress_update
                            asyncio.create_task(broadcast_rich_progress_update(task_id, data))
                        except Exception as e:
                            print(f"âš ï¸ WebSocket callback error: {e}")

                    result = loop.run_until_complete(
                        scrapy_service.run_spider_with_watchdog(
                            project_path=project.path,
                            spider_name=spider.name,
                            task_id=task_id,
                            settings=db_schedule.settings or {},
                            websocket_callback=websocket_callback
                        )
                    )

                    print(f"âœ… Legacy spider execution completed: {task_id}")

                except Exception as e:
                    print(f"âŒ Legacy spider execution error: {e}")
                finally:
                    loop.close()

            thread = threading.Thread(target=run_spider_background, daemon=True)
            thread.start()
            print(f"ğŸ”„ Legacy execution started for task: {task_id}")

    else:
        print(f"ğŸ§ª Testing mode: Skipping actual spider execution for task: {task_id}")

    # æœ€çµ‚å®Ÿè¡Œæ™‚åˆ»ã‚’æ›´æ–°
    db_schedule.last_run = datetime.now()

    # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’è¨ˆç®—
    try:
        cron = croniter(db_schedule.cron_expression, datetime.now())
        db_schedule.next_run = cron.get_next(datetime)
    except Exception:
        pass

    db.commit()

    return {
        "message": "Schedule executed successfully with realtime monitoring",
        "task_id": task_id,
        "schedule_id": schedule_id,
        "realtime": True,
        "command": "scrapy crawlwithwatchdog"
    }

@router.post(
    "/{schedule_id}/toggle",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ",
    description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚"
)
async def toggle_schedule(schedule_id: str, db: Session = Depends(get_db)):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ

    ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ID

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: åˆ‡ã‚Šæ›¿ãˆãŒæ­£å¸¸ã«å®Œäº†ã—ãŸå ´åˆ
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    db_schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
    if not db_schedule:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Schedule not found"
        )

    db_schedule.is_active = not db_schedule.is_active
    db.commit()
    db.refresh(db_schedule)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æƒ…å ±ã‚’å–å¾—
    project = db.query(DBProject).filter(DBProject.id == db_schedule.project_id).first()
    spider = db.query(DBSpider).filter(DBSpider.id == db_schedule.spider_id).first()

    # å®Œå…¨ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™
    schedule_dict = {
        "id": db_schedule.id,
        "name": db_schedule.name,
        "description": db_schedule.description,
        "cron_expression": db_schedule.cron_expression,
        "project_id": db_schedule.project_id,
        "spider_id": db_schedule.spider_id,
        "is_active": db_schedule.is_active,
        "last_run": db_schedule.last_run,
        "next_run": db_schedule.next_run,
        "created_at": db_schedule.created_at,
        "updated_at": db_schedule.updated_at,
        "settings": db_schedule.settings,
        "project_name": project.name if project else "N/A",
        "spider_name": spider.name if spider else "N/A"
    }

    return schedule_dict

@router.get(
    "/{schedule_id}/tasks",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œå±¥æ­´å–å¾—",
    description="æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè¡Œå±¥æ­´ï¼ˆã‚¿ã‚¹ã‚¯ä¸€è¦§ï¼‰ã‚’å–å¾—ã—ã¾ã™ã€‚"
)
async def get_schedule_tasks(
    schedule_id: str,
    limit: int = 20,
    offset: int = 0,
    status: str = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_active_user)
):
    """
    ## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œå±¥æ­´å–å¾—

    æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè¡Œå±¥æ­´ï¼ˆã‚¿ã‚¹ã‚¯ä¸€è¦§ï¼‰ã‚’å–å¾—ã—ã¾ã™ã€‚

    ### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - **schedule_id**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ID
    - **limit**: å–å¾—ä»¶æ•°ã®åˆ¶é™ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20)
    - **offset**: ã‚ªãƒ•ã‚»ãƒƒãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0)
    - **status**: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (optional)

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™
    - **404**: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    try:
        print(f"ğŸ” Getting schedule tasks for schedule_id: {schedule_id}")
        print(f"ğŸ” Parameters: limit={limit}, offset={offset}, status={status}")
        print(f"ğŸ” User: {current_user.email if current_user else 'None'}")

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å­˜åœ¨ç¢ºèª
        schedule = db.query(DBSchedule).filter(DBSchedule.id == schedule_id).first()
        if not schedule:
            print(f"âŒ Schedule not found: {schedule_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Schedule not found"
            )

        print(f"âœ… Schedule found: {schedule.name}")

        # æ¨©é™ãƒã‚§ãƒƒã‚¯
        is_admin = (current_user.role == UserRole.ADMIN or
                    current_user.role == "ADMIN" or
                    current_user.role == "admin")

        print(f"ğŸ” User role: {current_user.role}, is_admin: {is_admin}")

        if not is_admin:
            # ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            project = db.query(DBProject).filter(DBProject.id == schedule.project_id).first()
            if not project or project.user_id != current_user.id:
                print(f"âŒ Access denied for user {current_user.email}")
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="Access denied"
                )

        # ã‚¿ã‚¹ã‚¯ä¸€è¦§ã‚’å–å¾—
        query = db.query(DBTask).filter(DBTask.schedule_id == schedule_id)
        print(f"ğŸ” Base query created for schedule_id: {schedule_id}")

        if status:
            status_list = [s.strip().upper() for s in status.split(',')]
            query = query.filter(DBTask.status.in_(status_list))
            print(f"ğŸ” Status filter applied: {status_list}")

        # ç·ä»¶æ•°ã‚’å–å¾—
        total_count = query.count()
        print(f"ğŸ” Total count: {total_count}")

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨
        tasks = query.order_by(DBTask.created_at.desc()).offset(offset).limit(limit).all()
        print(f"ğŸ” Retrieved {len(tasks)} tasks")

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¤‰æ›
        task_list = []
        for task in tasks:
            try:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                status_str = task.status
                if hasattr(task.status, 'value'):
                    status_str = task.status.value
                elif hasattr(task.status, 'name'):
                    status_str = task.status.name
                else:
                    status_str = str(task.status)

                task_dict = {
                    "id": task.id,
                    "status": status_str,
                    "items_count": task.items_count or 0,
                    "requests_count": task.requests_count or 0,
                    "error_count": task.error_count or 0,
                    "started_at": task.started_at.isoformat() if task.started_at else None,
                    "finished_at": task.finished_at.isoformat() if task.finished_at else None,
                    "created_at": task.created_at.isoformat() if task.created_at else None,
                    "updated_at": task.updated_at.isoformat() if task.updated_at else None,
                    "log_level": task.log_level,
                    "settings": task.settings,
                    "celery_task_id": task.celery_task_id,
                    "error_message": getattr(task, 'error_message', None)
                }
                task_list.append(task_dict)
                print(f"âœ… Successfully converted task {task.id}: {status_str}")
            except Exception as e:
                print(f"âŒ Error converting task {task.id}: {str(e)}")
                import traceback
                traceback.print_exc()
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚¿ã‚¹ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                continue

        response = {
            "tasks": task_list,
            "total_count": total_count,
            "limit": limit,
            "offset": offset,
            "schedule_id": schedule_id
        }

        print(f"âœ… Successfully returning {len(task_list)} tasks")
        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Unexpected error in get_schedule_tasks: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get schedule tasks: {str(e)}"
        )

@router.get(
    "/pending-tasks/count",
    summary="å¾…æ©Ÿã‚¿ã‚¹ã‚¯æ•°å–å¾—",
    description="ç¾åœ¨å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚"
)
async def get_pending_tasks_count(db: Session = Depends(get_db)):
    """å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—"""
    try:
        pending_count = db.query(DBTask).filter(DBTask.status == TaskStatus.PENDING).count()

        # å¤ã„ã‚¿ã‚¹ã‚¯ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰ã®æ•°ã‚‚å–å¾—
        from datetime import datetime, timedelta
        cutoff_time = datetime.now() - timedelta(hours=24)
        old_pending_count = db.query(DBTask).filter(
            DBTask.status == TaskStatus.PENDING,
            DBTask.created_at < cutoff_time
        ).count()

        return {
            "total_pending": pending_count,
            "old_pending": old_pending_count,
            "recent_pending": pending_count - old_pending_count
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get pending tasks count: {str(e)}"
        )

@router.post(
    "/pending-tasks/reset",
    summary="å¾…æ©Ÿã‚¿ã‚¹ã‚¯ãƒªã‚»ãƒƒãƒˆ",
    description="å¤ã„å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã¨å­¤ç«‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™ã€‚"
)
async def reset_pending_tasks(
    request: ResetTasksRequest,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_active_user)
):
    """å¤ã„å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã¨å­¤ç«‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
    try:
        from datetime import datetime, timedelta

        # ç®¡ç†è€…æ¨©é™ãƒã‚§ãƒƒã‚¯
        is_admin = (current_user.role == UserRole.ADMIN or
                    current_user.role == "ADMIN" or
                    current_user.role == "admin")

        if not is_admin:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Admin privileges required"
            )

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        hours_back = request.hours_back
        cleanup_orphaned = request.cleanup_orphaned
        reset_all = request.reset_all

        print(f"ğŸ—‘ï¸ Starting task reset process...")
        print(f"  - Hours back: {hours_back}")
        print(f"  - Cleanup orphaned: {cleanup_orphaned}")
        print(f"  - Reset all: {reset_all}")
        print(f"  - User: {current_user.email}")

        cancelled_count = 0
        orphaned_count = 0
        running_count = 0

        if reset_all:
            # å…¨ã¦ã®RUNNINGã¨PENDINGã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            active_tasks = db.query(DBTask).filter(
                DBTask.status.in_([TaskStatus.RUNNING, TaskStatus.PENDING])
            ).all()

            print(f"ğŸ—‘ï¸ Cancelling ALL {len(active_tasks)} active tasks (RUNNING and PENDING)")
            for task in active_tasks:
                if task.status == TaskStatus.RUNNING:
                    print(f"  - Cancelling running task: {task.id[:8]}... (started: {task.started_at})")
                    running_count += 1
                else:
                    print(f"  - Cancelling pending task: {task.id[:8]}... (created: {task.created_at})")
                    cancelled_count += 1

                task.status = TaskStatus.CANCELLED
                task.finished_at = datetime.now()
        else:
            # 1. æŒ‡å®šæ™‚é–“ä»¥ä¸Šå‰ã®å¾…æ©Ÿä¸­ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            old_pending_tasks = db.query(DBTask).filter(
                DBTask.status == TaskStatus.PENDING,
                DBTask.created_at < cutoff_time
            ).all()

            print(f"ğŸ—‘ï¸ Cancelling {len(old_pending_tasks)} old pending tasks (older than {hours_back} hours)")
            for task in old_pending_tasks:
                print(f"  - Cancelling old task: {task.id[:8]}... (created: {task.created_at})")
                task.status = TaskStatus.CANCELLED
                task.finished_at = datetime.now()
                cancelled_count += 1

        # 2. å­¤ç«‹ã—ãŸå¾…æ©Ÿã‚¿ã‚¹ã‚¯ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€reset_allã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if cleanup_orphaned and not reset_all:
            # é–¢é€£ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå­˜åœ¨ã—ãªã„å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            all_pending_tasks = db.query(DBTask).filter(DBTask.status == TaskStatus.PENDING).all()

            for task in all_pending_tasks:
                # å¯¾å¿œã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                related_schedule = db.query(DBSchedule).filter(
                    DBSchedule.project_id == task.project_id,
                    DBSchedule.spider_id == task.spider_id
                ).first()

                if not related_schedule:
                    print(f"ğŸ—‘ï¸ Cancelling orphaned task: {task.id[:8]}... (no related schedule)")
                    task.status = TaskStatus.CANCELLED
                    task.finished_at = datetime.now()
                    orphaned_count += 1

        db.commit()

        # æ®‹ã‚Šã®å¾…æ©Ÿã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—
        remaining_pending = db.query(DBTask).filter(DBTask.status == TaskStatus.PENDING).count()
        remaining_running = db.query(DBTask).filter(DBTask.status == TaskStatus.RUNNING).count()

        if reset_all:
            total_cancelled = cancelled_count + running_count
            message = f"Successfully cancelled ALL active tasks: {running_count} running and {cancelled_count} pending tasks"
        else:
            message_parts = []
            if cancelled_count > 0:
                message_parts.append(f"{cancelled_count} old pending tasks")
            if orphaned_count > 0:
                message_parts.append(f"{orphaned_count} orphaned tasks")

            message = f"Successfully cancelled {' and '.join(message_parts) if message_parts else 'no tasks'}"
            total_cancelled = cancelled_count + orphaned_count

        return {
            "message": message,
            "cancelled_count": cancelled_count,
            "running_count": running_count,
            "orphaned_count": orphaned_count,
            "total_cancelled": total_cancelled,
            "remaining_pending": remaining_pending,
            "remaining_running": remaining_running,
            "hours_back": hours_back,
            "cleanup_orphaned": cleanup_orphaned,
            "reset_all": reset_all
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to reset pending tasks: {str(e)}"
        )

@router.get(
    "/scheduler/status",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ…‹å–å¾—",
    description="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ã‚’å–å¾—ã—ã¾ã™ã€‚"
)
async def get_scheduler_status():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ã‚’å–å¾—"""
    try:
        status = scheduler_service.get_status()
        return status
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get scheduler status: {str(e)}"
        )

@router.post(
    "/scheduler/health-check",
    summary="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯",
    description="å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å•é¡ŒãŒã‚ã‚Œã°ä¿®æ­£ã—ã¾ã™ã€‚"
)
async def scheduler_health_check(db: Session = Depends(get_db)):
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã¨è‡ªå‹•ä¿®æ­£"""
    try:
        # å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—
        schedules = db.query(DBSchedule).all()

        health_report = {
            "timestamp": datetime.now().isoformat(),
            "total_schedules": len(schedules),
            "healthy_schedules": 0,
            "fixed_schedules": 0,
            "error_schedules": 0,
            "issues": [],
            "fixes": []
        }

        for schedule in schedules:
            schedule_issues = []
            schedule_fixes = []

            # 1. Cronå¼ã®æ¤œè¨¼
            try:
                cron = croniter(schedule.cron_expression, datetime.now())
                next_run = cron.get_next(datetime)

                # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’æ›´æ–°ï¼ˆå¤ã„å ´åˆï¼‰
                if not schedule.next_run or schedule.next_run < datetime.now():
                    old_next_run = schedule.next_run
                    schedule.next_run = next_run
                    schedule_fixes.append(f"Updated next_run from {old_next_run} to {next_run}")

            except Exception as e:
                schedule_issues.append(f"Invalid cron expression: {e}")

            # 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
            if not schedule.project:
                schedule_issues.append("Associated project not found")
            if not schedule.spider:
                schedule_issues.append("Associated spider not found")

            # 3. å®Ÿè¡Œé »åº¦ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            try:
                cron_parts = schedule.cron_expression.split()
                if len(cron_parts) >= 1:
                    minute_part = cron_parts[0]
                    if minute_part.startswith('*/'):
                        interval = int(minute_part[2:])
                        if interval < 1:
                            schedule_issues.append("Execution interval too frequent (< 1 minute)")
                        elif interval > 1440:  # 24æ™‚é–“
                            schedule_issues.append("Execution interval too long (> 24 hours)")
            except:
                pass

            # 4. æœ€çµ‚å®Ÿè¡Œæ™‚åˆ»ã®å¦¥å½“æ€§
            if schedule.last_run and schedule.last_run > datetime.now():
                schedule.last_run = None
                schedule_fixes.append("Reset invalid last_run time")

            # çµæœã®é›†è¨ˆ
            if schedule_issues:
                health_report["error_schedules"] += 1
                health_report["issues"].append({
                    "schedule_id": schedule.id,
                    "schedule_name": schedule.name,
                    "issues": schedule_issues
                })
            else:
                health_report["healthy_schedules"] += 1

            if schedule_fixes:
                health_report["fixed_schedules"] += 1
                health_report["fixes"].append({
                    "schedule_id": schedule.id,
                    "schedule_name": schedule.name,
                    "fixes": schedule_fixes
                })

        # ä¿®æ­£ã‚’ã‚³ãƒŸãƒƒãƒˆ
        if health_report["fixed_schedules"] > 0:
            db.commit()

        # å¥å…¨æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        if health_report["total_schedules"] > 0:
            health_score = (health_report["healthy_schedules"] / health_report["total_schedules"]) * 100
            health_report["health_score"] = round(health_score, 1)
        else:
            health_report["health_score"] = 100.0

        return health_report

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to perform health check: {str(e)}"
        )

@router.post(
    "/clear-cache",
    summary="WebUIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢",
    description="WebUIã®è¡¨ç¤ºã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã€æœ€æ–°ã®çŠ¶æ…‹ã‚’å¼·åˆ¶æ›´æ–°ã—ã¾ã™ã€‚"
)
async def clear_webui_cache(
    db: Session = Depends(get_db),
    current_user = Depends(get_current_active_user)
):
    """
    ## WebUIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢

    WebUIã®è¡¨ç¤ºã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã€æœ€æ–°ã®çŠ¶æ…‹ã‚’å¼·åˆ¶æ›´æ–°ã—ã¾ã™ã€‚

    ### æ©Ÿèƒ½
    - ãƒ–ãƒ©ã‚¦ã‚¶ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç„¡åŠ¹åŒ–æŒ‡ç¤º
    - WebSocketæ¥ç¶šã®å†åŒæœŸ
    - æœ€æ–°ã®ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ã‚’å–å¾—

    ### ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    - **200**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãŒæ­£å¸¸ã«å®Œäº†ã—ãŸå ´åˆ
    - **500**: ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼
    """
    try:
        # æœ€æ–°ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—
        schedules = db.query(DBSchedule).filter(DBSchedule.is_active == True).all()

        # å„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ€æ–°ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ã‚’ç¢ºèª
        cache_clear_data = {
            "timestamp": datetime.now().isoformat(),
            "schedules_count": len(schedules),
            "active_tasks": [],
            "completed_tasks": []
        }

        for schedule in schedules:
            # å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ã‚’ç¢ºèª
            active_task = db.query(DBTask).filter(
                DBTask.schedule_id == schedule.id,
                DBTask.status.in_(['RUNNING', 'PENDING'])
            ).order_by(DBTask.created_at.desc()).first()

            if active_task:
                cache_clear_data["active_tasks"].append({
                    "schedule_id": schedule.id,
                    "schedule_name": schedule.name,
                    "task_id": active_task.id,
                    "status": active_task.status.value if hasattr(active_task.status, 'value') else active_task.status
                })

            # æœ€æ–°ã®å®Œäº†ã‚¿ã‚¹ã‚¯ã‚’ç¢ºèª
            completed_task = db.query(DBTask).filter(
                DBTask.schedule_id == schedule.id,
                DBTask.status.in_(['SUCCESS', 'FAILURE', 'REVOKED'])
            ).order_by(DBTask.created_at.desc()).first()

            if completed_task:
                cache_clear_data["completed_tasks"].append({
                    "schedule_id": schedule.id,
                    "schedule_name": schedule.name,
                    "task_id": completed_task.id,
                    "status": completed_task.status.value if hasattr(completed_task.status, 'value') else completed_task.status,
                    "items_count": completed_task.items_count or 0,
                    "requests_count": completed_task.requests_count or 0,
                    "finished_at": completed_task.finished_at
                })

        # WebSocketçµŒç”±ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢é€šçŸ¥ã‚’é€ä¿¡
        try:
            await realtime_websocket_manager.broadcast_message({
                "type": "cache_clear",
                "data": cache_clear_data,
                "message": "WebUIã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚"
            })
        except Exception as ws_error:
            print(f"WebSocket broadcast error: {ws_error}")

        return {
            "message": "WebUIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãŒå®Œäº†ã—ã¾ã—ãŸ",
            "cache_clear_data": cache_clear_data,
            "instructions": [
                "ãƒ–ãƒ©ã‚¦ã‚¶ã§F5ã‚­ãƒ¼ã¾ãŸã¯Ctrl+F5ã‚’æŠ¼ã—ã¦ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦ãã ã•ã„",
                "WebSocketæ¥ç¶šãŒè‡ªå‹•çš„ã«å†åŒæœŸã•ã‚Œã¾ã™",
                "æœ€æ–°ã®ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™"
            ]
        }

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )
