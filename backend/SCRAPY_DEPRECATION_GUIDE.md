# Scrapyéæ¨å¥¨é–¢æ•°å¯¾å¿œã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ¦‚è¦

Scrapy 2.13.0ä»¥é™ã§éæ¨å¥¨ã¨ãªã£ãŸé–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã®å¯¾å¿œçŠ¶æ³ã¨ç§»è¡Œã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

## âŒ **éæ¨å¥¨ã¨ãªã£ãŸé–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰**

### 1. **Spider.start_requests() â†’ Spider.start()**

#### **å¤‰æ›´å†…å®¹ï¼š**
- **éæ¨å¥¨ï¼š** `def start_requests(self):`
- **æ¨å¥¨ï¼š** `async def start(self):`

#### **ScrapyUIã§ã®å¯¾å¿œï¼š**
```python
# æ–°ã—ã„æ–¹æ³•ï¼ˆæ¨å¥¨ï¼‰
async def start(self):
    for url in self.start_urls:
        yield scrapy.Request(url, callback=self.parse)

# å¾Œæ–¹äº’æ›æ€§ï¼ˆéæ¨å¥¨ã ãŒå‹•ä½œã™ã‚‹ï¼‰
def start_requests(self):
    for url in self.start_urls:
        yield scrapy.Request(url, callback=self.parse)
```

#### **å½±éŸ¿ç¯„å›²ï¼š**
- âœ… `backend/app/templates/spider_templates.py` - å¯¾å¿œæ¸ˆã¿
- âš ï¸ æ—¢å­˜ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ« - æ‰‹å‹•æ›´æ–°ãŒå¿…è¦

### 2. **SpiderMiddleware.process_start_requests() â†’ process_start()**

#### **å¤‰æ›´å†…å®¹ï¼š**
- **éæ¨å¥¨ï¼š** `def process_start_requests(self, start_requests, spider):`
- **æ¨å¥¨ï¼š** `async def process_start(self, start):`

#### **ScrapyUIã§ã®å¯¾å¿œï¼š**
```python
# æ–°ã—ã„æ–¹æ³•ï¼ˆæ¨å¥¨ï¼‰
async def process_start(self, start):
    async for item_or_request in start:
        yield item_or_request

# å¾Œæ–¹äº’æ›æ€§ï¼ˆéæ¨å¥¨ã ãŒå‹•ä½œã™ã‚‹ï¼‰
def process_start_requests(self, start_requests, spider):
    for r in start_requests:
        yield r
```

#### **å½±éŸ¿ç¯„å›²ï¼š**
- âš ï¸ æ—¢å­˜ã®middlewareãƒ•ã‚¡ã‚¤ãƒ« - æ‰‹å‹•æ›´æ–°ãŒå¿…è¦

### 3. **ãã®ä»–ã®éæ¨å¥¨é–¢æ•°**

#### **scrapy.utils.urlé–¢æ•°ç¾¤**
```python
# éæ¨å¥¨
from scrapy.utils.url import canonicalize_url

# æ¨å¥¨
from w3lib.url import canonicalize_url
```

#### **scrapy.utils.versions**
```python
# éæ¨å¥¨
from scrapy.utils.versions import scrapy_components_versions

# æ¨å¥¨
from scrapy.utils.versions import get_versions
```

## ğŸ”§ **ç§»è¡Œæ‰‹é †**

### 1. **æ–°ã—ã„ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ä½œæˆæ™‚**

ScrapyUIã§æ–°ã—ã„ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆã™ã‚‹å ´åˆã€è‡ªå‹•çš„ã«æ–°ã—ã„å½¢å¼ãŒé©ç”¨ã•ã‚Œã¾ã™ï¼š

```python
class MySpider(scrapy.Spider):
    name = 'my_spider'
    
    # æ–°ã—ã„æ–¹æ³•ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
    async def start(self):
        for url in self.start_urls:
            yield scrapy.Request(url, callback=self.parse)
    
    # å¾Œæ–¹äº’æ›æ€§ã‚‚å«ã¾ã‚Œã‚‹
    def start_requests(self):
        for url in self.start_urls:
            yield scrapy.Request(url, callback=self.parse)
```

### 2. **æ—¢å­˜ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã®æ›´æ–°**

æ—¢å­˜ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’æ‰‹å‹•ã§æ›´æ–°ã™ã‚‹å ´åˆï¼š

```python
# æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰
def start_requests(self):
    for url in self.start_urls:
        yield scrapy.Request(url, callback=self.parse)

# æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¯æ®‹ã™ï¼‰
async def start(self):
    for url in self.start_urls:
        yield scrapy.Request(url, callback=self.parse)
```

### 3. **Middlewareã®æ›´æ–°**

æ—¢å­˜ã®middlewareã‚’æ›´æ–°ã™ã‚‹å ´åˆï¼š

```python
# æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰
def process_start_requests(self, start_requests, spider):
    for r in start_requests:
        yield r

# æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ 
async def process_start(self, start):
    async for item_or_request in start:
        yield item_or_request
```

## ğŸ“‹ **ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**

### âœ… **å¯¾å¿œæ¸ˆã¿**
- [x] ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ›´æ–°
- [x] æ–°ã—ã„`start()`ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿½åŠ 
- [x] å¾Œæ–¹äº’æ›æ€§ã®ç¶­æŒ

### âš ï¸ **ä»Šå¾Œã®å¯¾å¿œãŒå¿…è¦**
- [ ] æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æ›´æ–°
- [ ] æ—¢å­˜middlewareã®æ›´æ–°
- [ ] w3libé–¢æ•°ã¸ã®ç§»è¡Œ
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«

## ğŸš¨ **é‡è¦ãªæ³¨æ„äº‹é …**

### 1. **å¾Œæ–¹äº’æ›æ€§**
- ç¾åœ¨ã®ScrapyUIã¯æ–°æ—§ä¸¡æ–¹ã®å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆ
- æ—¢å­˜ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã¯å¼•ãç¶šãå‹•ä½œ
- æ®µéšçš„ãªç§»è¡ŒãŒå¯èƒ½

### 2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
- æ–°ã—ã„`start()`ãƒ¡ã‚½ãƒƒãƒ‰ã¯asyncå¯¾å¿œ
- ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨
- å¤§è¦æ¨¡ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§ã®æ”¹å–„

### 3. **å°†æ¥ã®å‰Šé™¤äºˆå®š**
- Scrapy 3.0ã§å¤ã„å½¢å¼ãŒå‰Šé™¤äºˆå®š
- æ—©ã‚ã®ç§»è¡Œã‚’æ¨å¥¨

## ğŸ”„ **è‡ªå‹•ç§»è¡Œãƒ„ãƒ¼ãƒ«ï¼ˆè¨ˆç”»ä¸­ï¼‰**

å°†æ¥çš„ã«ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’è¿½åŠ äºˆå®šï¼š

```bash
# æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è‡ªå‹•æ›´æ–°
scrapyui migrate --project my_project

# éæ¨å¥¨é–¢æ•°ã®æ¤œå‡º
scrapyui check-deprecated --project my_project

# ä¸€æ‹¬æ›´æ–°
scrapyui update-all-projects
```

## ğŸ“š **å‚è€ƒè³‡æ–™**

- [Scrapy 2.13.0 Release Notes](https://docs.scrapy.org/en/latest/news.html#scrapy-2-13-0-2025-05-08)
- [Scrapy Spider Documentation](https://docs.scrapy.org/en/latest/topics/spiders.html)
- [Scrapy Middleware Documentation](https://docs.scrapy.org/en/latest/topics/spider-middleware.html)

---

**ã“ã®ã‚¬ã‚¤ãƒ‰ã«ã‚ˆã‚Šã€ScrapyUIã¯æœ€æ–°ã®Scrapyãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¯¾å¿œã—ã€å°†æ¥çš„ãªäº’æ›æ€§ã‚’ç¢ºä¿ã—ã¾ã™ã€‚** ğŸš€
