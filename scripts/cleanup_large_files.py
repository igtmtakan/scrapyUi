#!/usr/bin/env python3
"""
ä¸è¦ãªå¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
import sys
import shutil
from pathlib import Path
from datetime import datetime, timedelta
import glob

def format_size(size_bytes):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} TB"

def cleanup_database_backups():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    patterns = [
        "backend/database/*.db.backup*",
        "backend/database/*.db.bak*",
        "backend/database/*.sqlite.backup*",
        "backend/database/*.sqlite.bak*",
        "**/*.db.backup*",
        "**/*.db.bak*",
    ]
    
    cleaned_files = []
    total_size = 0
    
    for pattern in patterns:
        for file_path in glob.glob(pattern, recursive=True):
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                try:
                    os.remove(file_path)
                    cleaned_files.append((file_path, file_size))
                    total_size += file_size
                    print(f"ğŸ—‘ï¸ å‰Šé™¤: {file_path} ({format_size(file_size)})")
                except OSError as e:
                    print(f"âŒ å‰Šé™¤å¤±æ•—: {file_path} - {e}")
    
    return cleaned_files, total_size

def cleanup_old_logs():
    """å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰"""
    log_patterns = [
        "logs/*.log",
        "scrapy_projects/*/logs/*.log",
        "**/*.log",
    ]
    
    cutoff_date = datetime.now() - timedelta(days=7)
    cleaned_files = []
    total_size = 0
    
    for pattern in log_patterns:
        for file_path in glob.glob(pattern, recursive=True):
            if os.path.exists(file_path):
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if file_mtime < cutoff_date:
                    file_size = os.path.getsize(file_path)
                    try:
                        os.remove(file_path)
                        cleaned_files.append((file_path, file_size))
                        total_size += file_size
                        print(f"ğŸ—‘ï¸ å¤ã„ãƒ­ã‚°å‰Šé™¤: {file_path} ({format_size(file_size)})")
                    except OSError as e:
                        print(f"âŒ å‰Šé™¤å¤±æ•—: {file_path} - {e}")
    
    return cleaned_files, total_size

def cleanup_temp_files():
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    temp_patterns = [
        "*.tmp",
        "*.temp",
        "**/*.tmp",
        "**/*.temp",
        "**/__pycache__",
        "**/.pytest_cache",
        "**/node_modules/.cache",
    ]
    
    cleaned_files = []
    total_size = 0
    
    for pattern in temp_patterns:
        for path in glob.glob(pattern, recursive=True):
            if os.path.exists(path):
                try:
                    if os.path.isfile(path):
                        file_size = os.path.getsize(path)
                        os.remove(path)
                        cleaned_files.append((path, file_size))
                        total_size += file_size
                        print(f"ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {path} ({format_size(file_size)})")
                    elif os.path.isdir(path) and any(name in path for name in ['__pycache__', '.pytest_cache', '.cache']):
                        dir_size = sum(os.path.getsize(os.path.join(dirpath, filename))
                                     for dirpath, dirnames, filenames in os.walk(path)
                                     for filename in filenames)
                        shutil.rmtree(path)
                        cleaned_files.append((path, dir_size))
                        total_size += dir_size
                        print(f"ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {path} ({format_size(dir_size)})")
                except OSError as e:
                    print(f"âŒ å‰Šé™¤å¤±æ•—: {path} - {e}")
    
    return cleaned_files, total_size

def cleanup_large_result_files():
    """å¤§ããªçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ1é€±é–“ä»¥ä¸Šå‰ã€50MBä»¥ä¸Šï¼‰"""
    result_patterns = [
        "scrapy_projects/*/*.jsonl",
        "scrapy_projects/*/*.json",
        "scrapy_projects/*/*.csv",
        "scrapy_projects/*/ranking_results.*",
        "scrapy_projects/*/stats_task_*.json",
    ]
    
    cutoff_date = datetime.now() - timedelta(days=7)
    size_limit = 50 * 1024 * 1024  # 50MB
    cleaned_files = []
    total_size = 0
    
    for pattern in result_patterns:
        for file_path in glob.glob(pattern, recursive=True):
            if os.path.exists(file_path):
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                file_size = os.path.getsize(file_path)
                
                if file_mtime < cutoff_date and file_size > size_limit:
                    try:
                        os.remove(file_path)
                        cleaned_files.append((file_path, file_size))
                        total_size += file_size
                        print(f"ğŸ—‘ï¸ å¤§ããªçµæœãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {file_path} ({format_size(file_size)})")
                    except OSError as e:
                        print(f"âŒ å‰Šé™¤å¤±æ•—: {file_path} - {e}")
    
    return cleaned_files, total_size

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ§¹ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹...")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 60)
    
    total_cleaned = 0
    total_size_cleaned = 0
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    db_files, db_size = cleanup_database_backups()
    total_cleaned += len(db_files)
    total_size_cleaned += db_size
    
    # å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("\nğŸ“ å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    log_files, log_size = cleanup_old_logs()
    total_cleaned += len(log_files)
    total_size_cleaned += log_size
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("\nğŸ—‚ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    temp_files, temp_size = cleanup_temp_files()
    total_cleaned += len(temp_files)
    total_size_cleaned += temp_size
    
    # å¤§ããªçµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("\nğŸ“Š å¤§ããªçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    result_files, result_size = cleanup_large_result_files()
    total_cleaned += len(result_files)
    total_size_cleaned += result_size
    
    print("\n" + "=" * 60)
    print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†!")
    print(f"ğŸ“ å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_cleaned}")
    print(f"ğŸ’¾ è§£æ”¾å®¹é‡: {format_size(total_size_cleaned)}")
    
    if total_cleaned == 0:
        print("ğŸ‰ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
