"""
ã‚¿ã‚¹ã‚¯çµ±è¨ˆæƒ…å ±ã®ä¿®æ­£ã‚µãƒ¼ãƒ“ã‚¹

çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿å–ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°
"""

import os
import json
import logging
from pathlib import Path
from typing import Tuple, Optional
from sqlalchemy.orm import Session
from backend.app.database import SessionLocal, Task

logger = logging.getLogger(__name__)

class TaskStatisticsFixer:
    """ã‚¿ã‚¹ã‚¯çµ±è¨ˆæƒ…å ±ã®ä¿®æ­£ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.base_projects_dir = Path("scrapy_projects")
    
    def fix_task_statistics(self, task_id: str) -> dict:
        """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®çµ±è¨ˆæƒ…å ±ã‚’ä¿®æ­£"""
        try:
            db = SessionLocal()
            try:
                # ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
                task = db.query(Task).filter(Task.id == task_id).first()
                if not task:
                    return {"success": False, "error": f"Task {task_id} not found"}
                
                # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®çµ±è¨ˆã‚’å–å¾—
                actual_items, actual_requests = self._get_file_statistics(task)
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°
                old_items = task.items_count
                old_requests = task.requests_count
                
                task.items_count = actual_items
                task.requests_count = actual_requests
                
                db.commit()
                
                logger.info(f"âœ… Fixed task {task_id}: items {old_items}â†’{actual_items}, requests {old_requests}â†’{actual_requests}")
                
                return {
                    "success": True,
                    "task_id": task_id,
                    "old_stats": {"items": old_items, "requests": old_requests},
                    "new_stats": {"items": actual_items, "requests": actual_requests},
                    "fixed": actual_items != old_items or actual_requests != old_requests
                }
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"âŒ Error fixing task statistics for {task_id}: {e}")
            return {"success": False, "error": str(e)}
    
    def fix_all_recent_tasks(self, hours_back: int = 24) -> dict:
        """æœ€è¿‘ã®ã‚¿ã‚¹ã‚¯ã®çµ±è¨ˆæƒ…å ±ã‚’ä¸€æ‹¬ä¿®æ­£"""
        try:
            from datetime import datetime, timedelta
            
            db = SessionLocal()
            try:
                # æœ€è¿‘ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
                cutoff_time = datetime.now() - timedelta(hours=hours_back)
                tasks = db.query(Task).filter(
                    Task.created_at >= cutoff_time,
                    Task.status == "FINISHED"
                ).all()
                
                results = {
                    "total_tasks": len(tasks),
                    "fixed_tasks": 0,
                    "errors": [],
                    "details": []
                }
                
                for task in tasks:
                    try:
                        result = self.fix_task_statistics(task.id)
                        if result["success"] and result["fixed"]:
                            results["fixed_tasks"] += 1
                            results["details"].append(result)
                    except Exception as e:
                        error_msg = f"Error fixing task {task.id}: {str(e)}"
                        results["errors"].append(error_msg)
                        logger.error(error_msg)
                
                logger.info(f"âœ… Fixed {results['fixed_tasks']}/{results['total_tasks']} tasks")
                return results
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"âŒ Error fixing all recent tasks: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_file_statistics(self, task: Task) -> Tuple[int, int]:
        """çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        try:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            project_path = task.project.path if task.project else task.project_id
            project_dir = self.base_projects_dir / project_path
            
            items_count = 0
            requests_count = 0
            
            # 1. çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªï¼ˆJSONLå½¢å¼ï¼‰
            result_file = project_dir / "results" / f"{task.id}.jsonl"
            if result_file.exists():
                try:
                    with open(result_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        items_count = len([line for line in lines if line.strip()])
                        requests_count = max(items_count + 5, 1)  # æ¨å®šå€¤
                        
                    logger.info(f"ğŸ“Š JSONL file found for task {task.id}: {items_count} items")
                    return items_count, requests_count
                except Exception as e:
                    logger.warning(f"âš ï¸ Error reading JSONL file for task {task.id}: {e}")
            
            # 2. JSONå½¢å¼ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            json_result_file = project_dir / "results" / f"{task.id}.json"
            if json_result_file.exists():
                try:
                    with open(json_result_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        items_count = len(data) if isinstance(data, list) else 1
                        requests_count = max(items_count + 5, 1)
                        
                    logger.info(f"ğŸ“Š JSON file found for task {task.id}: {items_count} items")
                    return items_count, requests_count
                except Exception as e:
                    logger.warning(f"âš ï¸ Error reading JSON file for task {task.id}: {e}")
            
            # 3. çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            stats_file = project_dir / f"stats_{task.id}.json"
            if stats_file.exists():
                try:
                    with open(stats_file, 'r', encoding='utf-8') as f:
                        stats = json.load(f)
                        items_count = stats.get('item_scraped_count', 0)
                        requests_count = stats.get('downloader/request_count', 0)
                        
                    logger.info(f"ğŸ“Š Stats file found for task {task.id}: items={items_count}, requests={requests_count}")
                    return items_count, requests_count
                except Exception as e:
                    logger.warning(f"âš ï¸ Error reading stats file for task {task.id}: {e}")
            
            logger.warning(f"âš ï¸ No result files found for task {task.id}")
            return 0, 0
            
        except Exception as e:
            logger.error(f"âŒ Error getting file statistics for task {task.id}: {e}")
            return 0, 0


# çµ±è¨ˆä¿®æ­£ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
task_statistics_fixer = TaskStatisticsFixer()
