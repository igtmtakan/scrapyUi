"""
çµæœãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹
ç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸScrapyã®çµæœã‚’WebUIã«åæ˜ ã•ã›ã‚‹
"""

import json
import os
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from sqlalchemy.orm import Session
from ..database import Task, Spider as DBSpider, Project as DBProject


class ResultSyncService:
    """çµæœãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self, base_projects_dir: str = "scrapy_projects"):
        self.base_projects_dir = Path(base_projects_dir)

    def scan_and_sync_results(self, db: Session) -> Dict:
        """å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦åŒæœŸ"""
        results = {
            "scanned_projects": 0,
            "synced_tasks": 0,
            "synced_items": 0,
            "errors": []
        }

        try:
            # å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
            for project_dir in self.base_projects_dir.iterdir():
                if project_dir.is_dir():
                    results["scanned_projects"] += 1

                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                    sync_result = self._sync_project_results(db, project_dir)
                    results["synced_tasks"] += sync_result["synced_tasks"]
                    results["synced_items"] += sync_result["synced_items"]
                    results["errors"].extend(sync_result["errors"])

            print(f"âœ… Result sync completed: {results}")
            return results

        except Exception as e:
            error_msg = f"Error in scan_and_sync_results: {str(e)}"
            results["errors"].append(error_msg)
            print(f"âŒ {error_msg}")
            return results

    def _sync_project_results(self, db: Session, project_dir: Path) -> Dict:
        """å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæœŸ"""
        results = {
            "synced_tasks": 0,
            "synced_items": 0,
            "errors": []
        }

        try:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œç´¢
            project_name = project_dir.name
            db_project = db.query(DBProject).filter(DBProject.path == project_name).first()

            if not db_project:
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã®å¤‰æ›ã‚’è©¦è¡Œ (admin_aiueo -> aiueo)
                if project_name.startswith('admin_'):
                    clean_name = project_name[6:]  # 'admin_'ã‚’é™¤å»
                    db_project = db.query(DBProject).filter(DBProject.name == clean_name).first()

                if not db_project:
                    return results

            print(f"ğŸ” Processing project: {project_name} -> {db_project.name}")

            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆJSONLã¨JSONã®ä¸¡æ–¹ï¼‰
            jsonl_files = list(project_dir.glob("*.jsonl"))
            json_files = list(project_dir.glob("*.json"))
            json_files = [f for f in json_files if f.name not in ['scrapy.cfg']]
            result_files = jsonl_files + json_files

            for result_file in result_files:
                try:
                    sync_result = self._sync_result_file(db, db_project, result_file)
                    if sync_result:
                        results["synced_tasks"] += 1
                        results["synced_items"] += sync_result["items_count"]
                        print(f"âœ… Synced: {result_file.name} ({sync_result['items_count']} items)")

                except Exception as e:
                    error_msg = f"Error syncing {result_file}: {str(e)}"
                    results["errors"].append(error_msg)
                    print(f"âŒ {error_msg}")

            return results

        except Exception as e:
            error_msg = f"Error processing project {project_dir}: {str(e)}"
            results["errors"].append(error_msg)
            print(f"âŒ {error_msg}")
            return results

    def _sync_result_file(self, db: Session, project: DBProject, result_file: Path) -> Optional[Dict]:
        """çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¿ã‚¹ã‚¯ã¨ã—ã¦åŒæœŸ"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦èª­ã¿è¾¼ã¿
            if result_file.suffix == '.jsonl':
                items = self._read_jsonl_file(result_file)
            else:
                items = self._read_json_file(result_file)

            if not items or len(items) == 0:
                return None

            # ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’æ¨æ¸¬
            spider_name = self._extract_spider_name(result_file.name, items)
            if not spider_name:
                return None

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’æ¤œç´¢
            db_spider = db.query(DBSpider).filter(
                DBSpider.project_id == project.id,
                DBSpider.name == spider_name
            ).first()

            if not db_spider:
                print(f"âš ï¸ Spider not found: {spider_name} in project {project.name}")
                return None

            # æ—¢å­˜ã®ã‚¿ã‚¹ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
            existing_task = db.query(Task).filter(
                Task.spider_id == db_spider.id,
                Task.items_count == len(items)
            ).first()

            if existing_task:
                print(f"ğŸ“‹ Task already exists for {spider_name} with {len(items)} items")
                return None

            # æ—¥æ™‚æƒ…å ±ã‚’æŠ½å‡º
            start_time, end_time = self._extract_timestamps(items, result_file)

            # æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
            new_task = Task(
                id=str(uuid.uuid4()),
                spider_id=db_spider.id,
                project_id=project.id,
                spider_name=spider_name,
                status="COMPLETED",
                items_count=len(items),
                requests_count=len(items) + 2,  # æ¨å®šå€¤
                started_at=start_time,
                finished_at=end_time,
                result_file=str(result_file),
                user_id=project.user_id
            )

            db.add(new_task)
            db.commit()

            return {
                "task_id": new_task.id,
                "items_count": len(items),
                "spider_name": spider_name
            }

        except Exception as e:
            db.rollback()
            raise e

    def _extract_spider_name(self, filename: str, items: List[Dict]) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã¾ãŸã¯ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’æŠ½å‡º"""
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬
        if "omocha20" in filename.lower():
            return "omocha20"
        elif "software20" in filename.lower():
            return "software20"

        # ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚è¿½åŠ å¯èƒ½
        if "enhanced" in filename.lower() or "improved" in filename.lower():
            return "software20"  # æ”¹å–„ç‰ˆã‚‚ software20 ã¨ã—ã¦æ‰±ã†

        # ã‚¿ã‚¹ã‚¯IDãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®æ¨æ¸¬
        if "results_" in filename.lower():
            # æœ€åˆã®ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’æ¨æ¸¬
            if items and len(items) > 0:
                first_item = items[0]
                if isinstance(first_item, dict):
                    # URLã‹ã‚‰ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼åã‚’æ¨æ¸¬
                    url = first_item.get('url', '')
                    if 'amazon.co.jp' in url and 'software' in url:
                        return "omocha20"

        return None

    def _extract_timestamps(self, items: List[Dict], result_file: Path) -> Tuple[datetime, datetime]:
        """ã‚¢ã‚¤ãƒ†ãƒ ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æ™‚æƒ…å ±ã‚’æŠ½å‡º"""
        try:
            # ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰æ—¥æ™‚æƒ…å ±ã‚’æŠ½å‡º
            if items and len(items) > 0:
                first_item = items[0]
                last_item = items[-1]

                # crawl_start_datetime ã‚’ä½¿ç”¨
                if "crawl_start_datetime" in first_item:
                    start_time = datetime.fromisoformat(first_item["crawl_start_datetime"])
                    if start_time.tzinfo is None:
                        start_time = start_time.replace(tzinfo=timezone.utc)
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ™‚åˆ»ã‚’ä½¿ç”¨
                    file_time = datetime.fromtimestamp(result_file.stat().st_mtime, tz=timezone.utc)
                    start_time = file_time

                # item_acquired_datetime ã‚’ä½¿ç”¨
                if "item_acquired_datetime" in last_item:
                    end_time = datetime.fromisoformat(last_item["item_acquired_datetime"])
                    if end_time.tzinfo is None:
                        end_time = end_time.replace(tzinfo=timezone.utc)
                else:
                    # é–‹å§‹æ™‚åˆ»ã‹ã‚‰æ¨å®š
                    end_time = start_time

                return start_time, end_time

        except Exception as e:
            print(f"âš ï¸ Error extracting timestamps: {e}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ™‚åˆ»
        file_time = datetime.fromtimestamp(result_file.stat().st_mtime, tz=timezone.utc)
        return file_time, file_time

    def _read_jsonl_file(self, file_path: Path) -> List[Dict]:
        """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        items = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line:  # ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                        try:
                            item = json.loads(line)
                            items.append(item)
                        except json.JSONDecodeError as e:
                            print(f"âš ï¸ JSONL Line {line_num}: JSON decode error - {e}")
                            continue
            print(f"ğŸ“Š JSONLèª­ã¿è¾¼ã¿å®Œäº†: {len(items)}ä»¶ from {file_path.name}")
            return items
        except Exception as e:
            print(f"âŒ JSONLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _read_json_file(self, file_path: Path) -> List[Dict]:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ­£å¸¸ãªJSONã¨ã—ã¦èª­ã¿è¾¼ã¿è©¦è¡Œ
            try:
                items = json.loads(content)
                if isinstance(items, list):
                    print(f"ğŸ“Š JSONèª­ã¿è¾¼ã¿å®Œäº†: {len(items)}ä»¶ from {file_path.name}")
                    return items
                else:
                    print(f"ğŸ“Š JSONèª­ã¿è¾¼ã¿å®Œäº†: 1ä»¶ from {file_path.name}")
                    return [items]
            except json.JSONDecodeError:
                # ä¸æ­£ãªJSONã®å ´åˆã¯ä¿®å¾©ã‚’è©¦è¡Œ
                print(f"âš ï¸ ä¸æ­£ãªJSONå½¢å¼ã‚’æ¤œå‡ºã€ä¿®å¾©ã‚’è©¦è¡Œ: {file_path.name}")
                return self._fix_malformed_json(content, file_path.name)
        except Exception as e:
            print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _fix_malformed_json(self, content: str, filename: str) -> List[Dict]:
        """ä¸æ­£ãªJSONã‚’ä¿®å¾©"""
        import re

        # JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡º
        pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(pattern, content)

        items = []
        for match in matches:
            try:
                obj = json.loads(match)
                items.append(obj)
            except json.JSONDecodeError:
                continue

        print(f"ğŸ”§ JSONä¿®å¾©å®Œäº†: {len(items)}ä»¶ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡º from {filename}")
        return items


# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
result_sync_service = ResultSyncService()
