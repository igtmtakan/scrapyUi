#!/usr/bin/env python3
"""
ScrapyUI Migration Comparison Report
æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã®æ¯”è¼ƒåˆ†æ
"""

import json
import requests
from datetime import datetime
from typing import Dict, List

def generate_comparison_report():
    """ç§»è¡Œæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    
    print("ğŸ“Š ScrapyUI ç§»è¡Œæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    print(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}")
    print()
    
    # 1. æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®æƒ…å ±
    print("ğŸ” æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ åˆ†æ")
    print("-" * 30)
    
    try:
        with open('/tmp/existing_schedules.json', 'r') as f:
            existing_schedules = json.load(f)
        
        with open('/tmp/project_spider_data.json', 'r') as f:
            project_data = json.load(f)
        
        print(f"ğŸ“‹ æ—¢å­˜ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°: {len(existing_schedules)}")
        print(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {len(project_data['projects'])}")
        print(f"ğŸ•·ï¸ ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼æ•°: {len(project_data['spiders'])}")
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°
        print("\nğŸ“‹ æ—¢å­˜ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°:")
        for schedule in existing_schedules:
            spider_info = project_data['spiders'].get(schedule['spider_id'], {})
            print(f"  â€¢ {schedule['name']}: {schedule['cron_expression']} ({spider_info.get('name', 'Unknown')})")
        
    except Exception as e:
        print(f"âŒ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    print()
    
    # 2. ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã®æƒ…å ±
    print("ğŸš€ ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åˆ†æ")
    print("-" * 30)
    
    try:
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        metrics_response = requests.get("http://localhost:8005/metrics")
        if metrics_response.status_code == 200:
            metrics = metrics_response.json()
            
            print(f"â±ï¸ ç¨¼åƒæ™‚é–“: {metrics['uptime']:.1f}ç§’")
            print(f"ğŸ“‹ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°: {metrics['stats']['schedules']}")
            print(f"âš™ï¸ ã‚¿ã‚¹ã‚¯æ•°: {metrics['stats']['tasks']}")
            print(f"ğŸ“Š çµæœæ•°: {metrics['stats']['results']}")
            
            if 'task_statuses' in metrics:
                print("\nğŸ“ˆ ã‚¿ã‚¹ã‚¯çŠ¶æ…‹åˆ†å¸ƒ:")
                for status, count in metrics['task_statuses'].items():
                    print(f"  â€¢ {status}: {count}å€‹")
        
        # ã‚¿ã‚¹ã‚¯è©³ç´°å–å¾—
        tasks_response = requests.get("http://localhost:8005/tasks")
        if tasks_response.status_code == 200:
            tasks = tasks_response.json()['tasks']
            
            print(f"\nâš™ï¸ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œå±¥æ­´:")
            for task in tasks:
                duration = "è¨ˆç®—ä¸­"
                if task.get('finished_at') and task.get('started_at'):
                    start = datetime.fromisoformat(task['started_at'])
                    end = datetime.fromisoformat(task['finished_at'])
                    duration = f"{(end - start).total_seconds():.1f}ç§’"
                
                print(f"  â€¢ {task['id']}: {task['status']} (å®Ÿè¡Œæ™‚é–“: {duration})")
        
        # çµæœè©³ç´°å–å¾—
        results_response = requests.get("http://localhost:8005/results")
        if results_response.status_code == 200:
            results = results_response.json()['results']
            
            print(f"\nğŸ“Š çµæœè©³ç´°:")
            total_items = 0
            total_pages = 0
            total_duration = 0
            
            for result in results:
                data = result['data']
                items = data.get('items', 0)
                pages = data.get('pages', 0)
                duration = data.get('duration', 0)
                
                total_items += items
                total_pages += pages
                total_duration += duration
                
                print(f"  â€¢ {result['id']}: {items}ã‚¢ã‚¤ãƒ†ãƒ , {pages}ãƒšãƒ¼ã‚¸, {duration}ç§’")
            
            if results:
                avg_items = total_items / len(results)
                avg_pages = total_pages / len(results)
                avg_duration = total_duration / len(results)
                
                print(f"\nğŸ“ˆ å¹³å‡å€¤:")
                print(f"  â€¢ ã‚¢ã‚¤ãƒ†ãƒ /ã‚¿ã‚¹ã‚¯: {avg_items:.1f}")
                print(f"  â€¢ ãƒšãƒ¼ã‚¸/ã‚¿ã‚¹ã‚¯: {avg_pages:.1f}")
                print(f"  â€¢ å®Ÿè¡Œæ™‚é–“/ã‚¿ã‚¹ã‚¯: {avg_duration:.1f}ç§’")
        
    except Exception as e:
        print(f"âŒ ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    print()
    
    # 3. ç§»è¡Œçµæœåˆ†æ
    print("ğŸ“Š ç§»è¡Œçµæœåˆ†æ")
    print("-" * 30)
    
    try:
        with open('/tmp/migration_report.json', 'r') as f:
            migration_report = json.load(f)
        
        stats = migration_report['migration_stats']
        
        print(f"â±ï¸ ç§»è¡Œå®Ÿè¡Œæ™‚é–“: {stats['start_time']} ï½ {stats['end_time']}")
        print(f"âœ… ç§»è¡ŒæˆåŠŸ: {stats['schedules_migrated']}å€‹")
        print(f"âŒ ç§»è¡Œå¤±æ•—: {stats['schedules_failed']}å€‹")
        print(f"ğŸš€ ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ä½œæˆ: {stats['tasks_created']}å€‹")
        print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœç”Ÿæˆ: {stats['results_generated']}å€‹")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {migration_report['success_rate']:.1f}%")
        
    except Exception as e:
        print(f"âŒ ç§»è¡Œçµæœåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    print()
    
    # 4. æ¯”è¼ƒåˆ†æ
    print("ğŸ” ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒåˆ†æ")
    print("-" * 30)
    
    print("ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒã€‘")
    print("æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ :")
    print("  â€¢ ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯æ§‹é€ ")
    print("  â€¢ Celeryä¾å­˜")
    print("  â€¢ å˜ä¸€éšœå®³ç‚¹ã‚ã‚Š")
    print("  â€¢ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å›°é›£")
    
    print("\nãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹:")
    print("  â€¢ ã‚µãƒ¼ãƒ“ã‚¹åˆ†é›¢")
    print("  â€¢ è»½é‡HTTP API")
    print("  â€¢ éšœå®³å±€æ‰€åŒ–")
    print("  â€¢ æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½")
    
    print("\nã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã€‘")
    print("æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ :")
    print("  â€¢ Celery Workerä¸å®‰å®š")
    print("  â€¢ ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å•é¡Œ")
    print("  â€¢ å¾©æ—§ã«æ™‚é–“è¦")
    
    print("\nãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹:")
    print("  â€¢ å®‰å®šã—ãŸå®Ÿè¡Œ")
    print("  â€¢ è»½é‡ãƒ—ãƒ­ã‚»ã‚¹")
    print("  â€¢ é«˜é€Ÿå¾©æ—§")
    
    print("\nã€é‹ç”¨æ€§æ¯”è¼ƒã€‘")
    print("æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ :")
    print("  â€¢ è¤‡é›‘ãªä¾å­˜é–¢ä¿‚")
    print("  â€¢ ãƒ‡ãƒãƒƒã‚°å›°é›£")
    print("  â€¢ éƒ¨åˆ†æ›´æ–°ä¸å¯")
    
    print("\nãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹:")
    print("  â€¢ ç‹¬ç«‹ãƒ‡ãƒ—ãƒ­ã‚¤")
    print("  â€¢ æ˜ç¢ºãªè²¬ä»»åˆ†é›¢")
    print("  â€¢ æ®µéšçš„æ›´æ–°å¯èƒ½")
    
    print()
    
    # 5. æ¨å¥¨äº‹é …
    print("ğŸ’¡ æ¨å¥¨äº‹é …")
    print("-" * 30)
    
    print("ã€çŸ­æœŸçš„å¯¾å¿œã€‘")
    print("1. ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç’°å¢ƒã®æœ¬æ ¼æ§‹ç¯‰")
    print("2. Docker/Kubernetesç’°å¢ƒæ•´å‚™")
    print("3. ç›£è¦–ãƒ»ãƒ­ã‚°åŸºç›¤æ§‹ç¯‰")
    
    print("\nã€ä¸­æœŸçš„å¯¾å¿œã€‘")
    print("1. æ®µéšçš„ç§»è¡Œè¨ˆç”»ç­–å®š")
    print("2. ãƒ‡ãƒ¼ã‚¿ç§»è¡Œãƒ„ãƒ¼ãƒ«é–‹ç™º")
    print("3. é‹ç”¨æ‰‹é †æ›¸ä½œæˆ")
    
    print("\nã€é•·æœŸçš„å¯¾å¿œã€‘")
    print("1. å®Œå…¨ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–")
    print("2. è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Ÿè£…")
    print("3. é«˜å¯ç”¨æ€§æ§‹æˆå®Ÿç¾")
    
    print()
    print("=" * 60)
    print("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")

if __name__ == "__main__":
    generate_comparison_report()
