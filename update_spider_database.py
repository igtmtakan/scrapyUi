#!/usr/bin/env python3
"""
ScrapyUIãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã§æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sqlite3
import os
import sys
from pathlib import Path

def update_spider_code_in_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã§æ›´æ–°"""

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    db_path = Path("backend/scrapy_ui.db")

    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return False

    # æœ€æ–°ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    spider_file = Path("user_scripts/admin-user-id/optimized_puppeteer_scraper.py")

    if not spider_file.exists():
        print(f"âŒ ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {spider_file}")
        return False

    try:
        # æœ€æ–°ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿å–ã‚Š
        with open(spider_file, 'r', encoding='utf-8') as f:
            latest_code = f.read()

        print(f"âœ… æœ€æ–°ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸ ({len(latest_code)} æ–‡å­—)")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # æ—¢å­˜ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’æ¤œç´¢
        cursor.execute("""
            SELECT id, name, code FROM spiders
            WHERE name = 'optimized_puppeteer_scraper'
        """)

        spiders = cursor.fetchall()

        if not spiders:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«optimized_puppeteer_scraperãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("æ–°ã—ã„ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã¨ã—ã¦è¿½åŠ ã—ã¾ã™...")

            # æ–°ã—ã„ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã¨ã—ã¦è¿½åŠ 
            import uuid
            spider_id = str(uuid.uuid4())

            cursor.execute("""
                INSERT INTO spiders (id, name, code, template, settings, project_id, user_id, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now'), datetime('now'))
            """, (
                spider_id,
                'optimized_puppeteer_scraper',
                latest_code,
                'advanced',
                '{}',
                'default-project',
                'admin-user-id'
            ))

            print(f"âœ… æ–°ã—ã„ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã¾ã—ãŸ (ID: {spider_id})")
        else:
            # æ—¢å­˜ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’å¼·åˆ¶æ›´æ–°
            for spider_id, spider_name, old_code in spiders:
                print(f"ğŸ”„ ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’å¼·åˆ¶æ›´æ–°ä¸­: {spider_name} (ID: {spider_id})")
                print(f"   å¤ã„ã‚³ãƒ¼ãƒ‰: {len(old_code)} æ–‡å­—")
                print(f"   æ–°ã—ã„ã‚³ãƒ¼ãƒ‰: {len(latest_code)} æ–‡å­—")

                # å¤ã„ã‚³ãƒ¼ãƒ‰ã«å•é¡Œã®ã‚ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if "from scrapy_ui.nodejs_client import NodeJSClient" in old_code:
                    print("   âš ï¸ å¤ã„ã‚³ãƒ¼ãƒ‰ã«å•é¡Œã®ã‚ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")

                cursor.execute("""
                    UPDATE spiders
                    SET code = ?, updated_at = datetime('now')
                    WHERE id = ?
                """, (latest_code, spider_id))

                print(f"âœ… ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’å¼·åˆ¶æ›´æ–°ã—ã¾ã—ãŸ: {spider_name}")

                # æ›´æ–°å¾Œã®ç¢ºèª
                cursor.execute("SELECT code FROM spiders WHERE id = ?", (spider_id,))
                updated_code = cursor.fetchone()[0]
                if "from scrapy_ui.nodejs_client import NodeJSClient" not in updated_code:
                    print("   âœ… å•é¡Œã®ã‚ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒé™¤å»ã•ã‚Œã¾ã—ãŸ")
                else:
                    print("   âŒ ã¾ã å•é¡Œã®ã‚ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæ®‹ã£ã¦ã„ã¾ã™")

        # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
        conn.commit()

        # æ›´æ–°å¾Œã®ç¢ºèª
        cursor.execute("""
            SELECT id, name, LENGTH(code) as code_length
            FROM spiders
            WHERE name = 'optimized_puppeteer_scraper'
        """)

        updated_spiders = cursor.fetchall()
        print(f"\nğŸ“Š æ›´æ–°å¾Œã®çŠ¶æ…‹:")
        for spider_id, spider_name, code_length in updated_spiders:
            print(f"   ID: {spider_id}")
            print(f"   åå‰: {spider_name}")
            print(f"   ã‚³ãƒ¼ãƒ‰é•·: {code_length} æ–‡å­—")

        conn.close()
        return True

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ ScrapyUIãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    print("=" * 50)

    # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    current_dir = Path.cwd()
    print(f"ğŸ“ ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {current_dir}")

    # ScrapyUIã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
    if current_dir.name != "scrapyUI":
        scrapy_ui_dir = current_dir / "scrapyUI"
        if scrapy_ui_dir.exists():
            os.chdir(scrapy_ui_dir)
            print(f"ğŸ“ ScrapyUIãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•: {scrapy_ui_dir}")
        else:
            print("âš ï¸ ScrapyUIãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã‚’å®Ÿè¡Œ
    success = update_spider_code_in_database()

    if success:
        print("\nğŸ‰ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ’¡ ã“ã‚Œã§ã€WebUIã‹ã‚‰æœ€æ–°ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã¾ã™")
    else:
        print("\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return 1

    return 0

if __name__ == "__main__":
    sys.exit(main())
